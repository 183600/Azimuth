// Azimuth Premium Serialization Tests
// é«˜è´¨é‡åºåˆ—åŒ–ååºåˆ—åŒ–å®Œæ•´æ€§æµ‹è¯•ç”¨ä¾‹
// ä¸“æ³¨äºæµ‹è¯•é¥æµ‹ç³»ç»Ÿæ•°æ®çš„åºåˆ—åŒ–å’Œååºåˆ—åŒ–å®Œæ•´æ€§å’Œä¸€è‡´æ€§

// æµ‹è¯•1: AttributeValueåºåˆ—åŒ–ååºåˆ—åŒ–æµ‹è¯•
test "AttributeValueåºåˆ—åŒ–ååºåˆ—åŒ–æµ‹è¯•" {
  // 1. æµ‹è¯•StringValueåºåˆ—åŒ–ååºåˆ—åŒ–
  let original_string = AttributeValue::StringValue("é¥æµ‹æ•°æ®å¤„ç†ç³»ç»Ÿ")
  
  // æ¨¡æ‹Ÿåºåˆ—åŒ–è¿‡ç¨‹
  let serialized_string = "StringValue:é¥æµ‹æ•°æ®å¤„ç†ç³»ç»Ÿ"
  
  // æ¨¡æ‹Ÿååºåˆ—åŒ–è¿‡ç¨‹
  let deserialized_string = match serialized_string.split(":")[0] {
    "StringValue" => AttributeValue::StringValue(serialized_string.split(":")[1])
    _ => AttributeValue::StringValue("") // é»˜è®¤å€¼
  }
  
  // éªŒè¯åºåˆ—åŒ–ååºåˆ—åŒ–ä¸€è‡´æ€§
  match deserialized_string {
    AttributeValue::StringValue(s) => {
      assert_eq(s, "é¥æµ‹æ•°æ®å¤„ç†ç³»ç»Ÿ")
      assert_eq(s.length(), 6)
    }
    _ => assert_true(false, "StringValueååºåˆ—åŒ–å¤±è´¥")
  }
  
  // 2. æµ‹è¯•IntValueåºåˆ—åŒ–ååºåˆ—åŒ–
  let original_int = AttributeValue::IntValue(42)
  
  // æ¨¡æ‹Ÿåºåˆ—åŒ–è¿‡ç¨‹
  let serialized_int = "IntValue:42"
  
  // æ¨¡æ‹Ÿååºåˆ—åŒ–è¿‡ç¨‹
  let deserialized_int = match serialized_int.split(":")[0] {
    "IntValue" => AttributeValue::IntValue(serialized_int.split(":")[1].to_int())
    _ => AttributeValue::IntValue(0) // é»˜è®¤å€¼
  }
  
  // éªŒè¯åºåˆ—åŒ–ååºåˆ—åŒ–ä¸€è‡´æ€§
  match deserialized_int {
    AttributeValue::IntValue(i) => {
      assert_eq(i, 42)
    }
    _ => assert_true(false, "IntValueååºåˆ—åŒ–å¤±è´¥")
  }
  
  // 3. æµ‹è¯•FloatValueåºåˆ—åŒ–ååºåˆ—åŒ–
  let original_float = AttributeValue::FloatValue(3.14159)
  
  // æ¨¡æ‹Ÿåºåˆ—åŒ–è¿‡ç¨‹
  let serialized_float = "FloatValue:3.14159"
  
  // æ¨¡æ‹Ÿååºåˆ—åŒ–è¿‡ç¨‹
  let deserialized_float = match serialized_float.split(":")[0] {
    "FloatValue" => AttributeValue::FloatValue(serialized_float.split(":")[1].to_double())
    _ => AttributeValue::FloatValue(0.0) // é»˜è®¤å€¼
  }
  
  // éªŒè¯åºåˆ—åŒ–ååºåˆ—åŒ–ä¸€è‡´æ€§
  match deserialized_float {
    AttributeValue::FloatValue(f) => {
      assert_true(f > 3.14 && f < 3.15)
    }
    _ => assert_true(false, "FloatValueååºåˆ—åŒ–å¤±è´¥")
  }
  
  // 4. æµ‹è¯•BoolValueåºåˆ—åŒ–ååºåˆ—åŒ–
  let original_bool = AttributeValue::BoolValue(true)
  
  // æ¨¡æ‹Ÿåºåˆ—åŒ–è¿‡ç¨‹
  let serialized_bool = "BoolValue:true"
  
  // æ¨¡æ‹Ÿååºåˆ—åŒ–è¿‡ç¨‹
  let deserialized_bool = match serialized_bool.split(":")[0] {
    "BoolValue" => AttributeValue::BoolValue(serialized_bool.split(":")[1] == "true")
    _ => AttributeValue::BoolValue(false) // é»˜è®¤å€¼
  }
  
  // éªŒè¯åºåˆ—åŒ–ååºåˆ—åŒ–ä¸€è‡´æ€§
  match deserialized_bool {
    AttributeValue::BoolValue(b) => {
      assert_true(b)
    }
    _ => assert_true(false, "BoolValueååºåˆ—åŒ–å¤±è´¥")
  }
  
  // 5. æµ‹è¯•ArrayStringValueåºåˆ—åŒ–ååºåˆ—åŒ–
  let original_string_array = AttributeValue::ArrayStringValue(["item1", "item2", "item3"])
  
  // æ¨¡æ‹Ÿåºåˆ—åŒ–è¿‡ç¨‹
  let serialized_string_array = "ArrayStringValue:item1,item2,item3"
  
  // æ¨¡æ‹Ÿååºåˆ—åŒ–è¿‡ç¨‹
  let deserialized_string_array = match serialized_string_array.split(":")[0] {
    "ArrayStringValue" => {
      let items = serialized_string_array.split(":")[1].split(",")
      AttributeValue::ArrayStringValue(items)
    }
    _ => AttributeValue::ArrayStringValue([]) // é»˜è®¤å€¼
  }
  
  // éªŒè¯åºåˆ—åŒ–ååºåˆ—åŒ–ä¸€è‡´æ€§
  match deserialized_string_array {
    AttributeValue::ArrayStringValue(arr) => {
      assert_eq(arr.length(), 3)
      assert_eq(arr[0], "item1")
      assert_eq(arr[1], "item2")
      assert_eq(arr[2], "item3")
    }
    _ => assert_true(false, "ArrayStringValueååºåˆ—åŒ–å¤±è´¥")
  }
  
  // 6. æµ‹è¯•ArrayIntValueåºåˆ—åŒ–ååºåˆ—åŒ–
  let original_int_array = AttributeValue::ArrayIntValue([1, 2, 3, 4, 5])
  
  // æ¨¡æ‹Ÿåºåˆ—åŒ–è¿‡ç¨‹
  let serialized_int_array = "ArrayIntValue:1,2,3,4,5"
  
  // æ¨¡æ‹Ÿååºåˆ—åŒ–è¿‡ç¨‹
  let deserialized_int_array = match serialized_int_array.split(":")[0] {
    "ArrayIntValue" => {
      let items_str = serialized_int_array.split(":")[1]
      let items_str_list = items_str.split(",")
      let mut items = []
      for item_str in items_str_list {
        items = items.push(item_str.to_int())
      }
      AttributeValue::ArrayIntValue(items)
    }
    _ => AttributeValue::ArrayIntValue([]) // é»˜è®¤å€¼
  }
  
  // éªŒè¯åºåˆ—åŒ–ååºåˆ—åŒ–ä¸€è‡´æ€§
  match deserialized_int_array {
    AttributeValue::ArrayIntValue(arr) => {
      assert_eq(arr.length(), 5)
      assert_eq(arr[0], 1)
      assert_eq(arr[4], 5)
    }
    _ => assert_true(false, "ArrayIntValueååºåˆ—åŒ–å¤±è´¥")
  }
}

// æµ‹è¯•2: SpanContextåºåˆ—åŒ–ååºåˆ—åŒ–æµ‹è¯•
test "SpanContextåºåˆ—åŒ–ååºåˆ—åŒ–æµ‹è¯•" {
  // 1. æµ‹è¯•åŸºæœ¬SpanContextåºåˆ—åŒ–ååºåˆ—åŒ–
  let original_context = SpanContext({
    trace_id: "12345678901234567890123456789012",
    span_id: "1234567890123456",
    sampled: true,
    trace_state: "key=value1,key2=value2"
  })
  
  // æ¨¡æ‹Ÿåºåˆ—åŒ–è¿‡ç¨‹
  let serialized_context = original_context.trace_id + "|" + 
                          original_context.span_id + "|" + 
                          (if original_context.sampled { "true" } else { "false" }) + "|" + 
                          original_context.trace_state
  
  // æ¨¡æ‹Ÿååºåˆ—åŒ–è¿‡ç¨‹
  let parts = serialized_context.split("|")
  let deserialized_context = SpanContext({
    trace_id: parts[0],
    span_id: parts[1],
    sampled: parts[2] == "true",
    trace_state: parts[3]
  })
  
  // éªŒè¯åºåˆ—åŒ–ååºåˆ—åŒ–ä¸€è‡´æ€§
  assert_eq(deserialized_context.trace_id, original_context.trace_id)
  assert_eq(deserialized_context.span_id, original_context.span_id)
  assert_eq(deserialized_context.sampled, original_context.sampled)
  assert_eq(deserialized_context.trace_state, original_context.trace_state)
  
  // 2. æµ‹è¯•æœªé‡‡æ ·çš„SpanContextåºåˆ—åŒ–ååºåˆ—åŒ–
  let unsampled_context = SpanContext({
    trace_id: "abcdef0123456789abcdef0123456789",
    span_id: "abcdef0123456789",
    sampled: false,
    trace_state: ""
  })
  
  // æ¨¡æ‹Ÿåºåˆ—åŒ–è¿‡ç¨‹
  let serialized_unsampled = unsampled_context.trace_id + "|" + 
                            unsampled_context.span_id + "|" + 
                            (if unsampled_context.sampled { "true" } else { "false" }) + "|" + 
                            unsampled_context.trace_state
  
  // æ¨¡æ‹Ÿååºåˆ—åŒ–è¿‡ç¨‹
  let unsampled_parts = serialized_unsampled.split("|")
  let deserialized_unsampled = SpanContext({
    trace_id: unsampled_parts[0],
    span_id: unsampled_parts[1],
    sampled: unsampled_parts[2] == "true",
    trace_state: unsampled_parts[3]
  })
  
  // éªŒè¯åºåˆ—åŒ–ååºåˆ—åŒ–ä¸€è‡´æ€§
  assert_eq(deserialized_unsampled.trace_id, unsampled_context.trace_id)
  assert_eq(deserialized_unsampled.span_id, unsampled_context.span_id)
  assert_eq(deserialized_unsampled.sampled, unsampled_context.sampled)
  assert_eq(deserialized_unsampled.trace_state, unsampled_context.trace_state)
  
  // 3. æµ‹è¯•åŒ…å«ç‰¹æ®Šå­—ç¬¦çš„trace_stateåºåˆ—åŒ–ååºåˆ—åŒ–
  let special_context = SpanContext({
    trace_id: "11111111111111111111111111111111",
    span_id: "1111111111111111",
    sampled: true,
    trace_state: "key=value!@#$%,key2=ä¸­æ–‡æµ‹è¯•,key3=ğŸŒŸ"
  })
  
  // æ¨¡æ‹Ÿåºåˆ—åŒ–è¿‡ç¨‹
  let serialized_special = special_context.trace_id + "|" + 
                           special_context.span_id + "|" + 
                           (if special_context.sampled { "true" } else { "false" }) + "|" + 
                           special_context.trace_state
  
  // æ¨¡æ‹Ÿååºåˆ—åŒ–è¿‡ç¨‹
  let special_parts = serialized_special.split("|")
  let deserialized_special = SpanContext({
    trace_id: special_parts[0],
    span_id: special_parts[1],
    sampled: special_parts[2] == "true",
    trace_state: special_parts[3]
  })
  
  // éªŒè¯åºåˆ—åŒ–ååºåˆ—åŒ–ä¸€è‡´æ€§
  assert_eq(deserialized_special.trace_id, special_context.trace_id)
  assert_eq(deserialized_special.span_id, special_context.span_id)
  assert_eq(deserialized_special.sampled, special_context.sampled)
  assert_eq(deserialized_special.trace_state, special_context.trace_state)
  assert_true(deserialized_special.trace_state.contains("ä¸­æ–‡æµ‹è¯•"))
  assert_true(deserialized_special.trace_state.contains("ğŸŒŸ"))
}

// æµ‹è¯•3: Baggageåºåˆ—åŒ–ååºåˆ—åŒ–æµ‹è¯•
test "Baggageåºåˆ—åŒ–ååºåˆ—åŒ–æµ‹è¯•" {
  // 1. æµ‹è¯•åŸºæœ¬Baggageåºåˆ—åŒ–ååºåˆ—åŒ–
  let original_baggage = Baggage({
    entries: [
      ("user.id", "user123"),
      ("request.id", "req456"),
      ("session.id", "sess789")
    ]
  })
  
  // æ¨¡æ‹Ÿåºåˆ—åŒ–è¿‡ç¨‹
  let mut serialized_pairs = []
  for (key, value) in original_baggage.entries {
    serialized_pairs = serialized_pairs.push(key + "=" + value)
  }
  let serialized_baggage = serialized_pairs.join(",")
  
  // æ¨¡æ‹Ÿååºåˆ—åŒ–è¿‡ç¨‹
  let pairs = serialized_baggage.split(",")
  let mut deserialized_entries = []
  for pair in pairs {
    let kv = pair.split("=")
    if kv.length() >= 2 {
      deserialized_entries = deserialized_entries.push((kv[0], kv[1]))
    }
  }
  let deserialized_baggage = Baggage({ entries: deserialized_entries })
  
  // éªŒè¯åºåˆ—åŒ–ååºåˆ—åŒ–ä¸€è‡´æ€§
  assert_eq(deserialized_baggage.entries.length(), original_baggage.entries.length())
  
  for (key, value) in original_baggage.entries {
    let mut found = false
    for (d_key, d_value) in deserialized_baggage.entries {
      if d_key == key && d_value == value {
        found = true
        break
      }
    }
    assert_true(found, "é”®å€¼å¯¹ " + key + "=" + value + " åº”è¯¥åœ¨ååºåˆ—åŒ–ç»“æœä¸­æ‰¾åˆ°")
  }
  
  // 2. æµ‹è¯•åŒ…å«ç‰¹æ®Šå­—ç¬¦çš„Baggageåºåˆ—åŒ–ååºåˆ—åŒ–
  let special_baggage = Baggage({
    entries: [
      ("special.key!@#$%", "special.value!@#$%"),
      ("unicode.key.ä¸­æ–‡", "unicode.value.ğŸŒŸ"),
      ("empty.value", ""),
      ("equals.key=value", "value=with=equals")
    ]
  })
  
  // æ¨¡æ‹Ÿåºåˆ—åŒ–è¿‡ç¨‹ï¼ˆéœ€è¦è½¬ä¹‰ç‰¹æ®Šå­—ç¬¦ï¼‰
  let mut special_serialized_pairs = []
  for (key, value) in special_baggage.entries {
    // ç®€åŒ–çš„è½¬ä¹‰å¤„ç†
    let escaped_key = key.replace("=", "\\=")
    let escaped_value = value.replace("=", "\\=")
    special_serialized_pairs = special_serialized_pairs.push(escaped_key + "=" + escaped_value)
  }
  let serialized_special_baggage = special_serialized_pairs.join(",")
  
  // æ¨¡æ‹Ÿååºåˆ—åŒ–è¿‡ç¨‹ï¼ˆéœ€è¦åè½¬ä¹‰ï¼‰
  let special_pairs = serialized_special_baggage.split(",")
  let mut special_deserialized_entries = []
  for pair in special_pairs {
    let kv = pair.split("=")
    if kv.length() >= 2 {
      // ç®€åŒ–çš„åè½¬ä¹‰å¤„ç†
      let unescaped_key = kv[0].replace("\\=", "=")
      let unescaped_value = kv[1].replace("\\=", "=")
      special_deserialized_entries = special_deserialized_entries.push((unescaped_key, unescaped_value))
    }
  }
  let deserialized_special_baggage = Baggage({ entries: special_deserialized_entries })
  
  // éªŒè¯åºåˆ—åŒ–ååºåˆ—åŒ–ä¸€è‡´æ€§
  assert_eq(deserialized_special_baggage.entries.length(), special_baggage.entries.length())
  
  for (key, value) in special_baggage.entries {
    let mut found = false
    for (d_key, d_value) in deserialized_special_baggage.entries {
      if d_key == key && d_value == value {
        found = true
        break
      }
    }
    assert_true(found, "ç‰¹æ®Šé”®å€¼å¯¹ " + key + "=" + value + " åº”è¯¥åœ¨ååºåˆ—åŒ–ç»“æœä¸­æ‰¾åˆ°")
  }
  
  // 3. æµ‹è¯•ç©ºBaggageåºåˆ—åŒ–ååºåˆ—åŒ–
  let empty_baggage = Baggage({ entries: [] })
  
  // æ¨¡æ‹Ÿåºåˆ—åŒ–è¿‡ç¨‹
  let serialized_empty_baggage = ""
  
  // æ¨¡æ‹Ÿååºåˆ—åŒ–è¿‡ç¨‹
  let deserialized_empty_baggage = if serialized_empty_baggage == "" {
    Baggage({ entries: [] })
  } else {
    let pairs = serialized_empty_baggage.split(",")
    let mut entries = []
    for pair in pairs {
      let kv = pair.split("=")
      if kv.length() >= 2 {
        entries = entries.push((kv[0], kv[1]))
      }
    }
    Baggage({ entries: entries })
  }
  
  // éªŒè¯åºåˆ—åŒ–ååºåˆ—åŒ–ä¸€è‡´æ€§
  assert_eq(deserialized_empty_baggage.entries.length(), 0)
}

// æµ‹è¯•4: TextMapCarrieråºåˆ—åŒ–ååºåˆ—åŒ–æµ‹è¯•
test "TextMapCarrieråºåˆ—åŒ–ååºåˆ—åŒ–æµ‹è¯•" {
  // 1. æµ‹è¯•åŸºæœ¬TextMapCarrieråºåˆ—åŒ–ååºåˆ—åŒ–
  let original_carrier = TextMapCarrier({
    headers: [
      ("traceparent", "00-12345678901234567890123456789012-1234567890123456-01"),
      ("tracestate", "key=value1,key2=value2"),
      ("baggage", "user.id=user123,request.id=req456"),
      ("x-request-id", "req-123456"),
      ("content-type", "application/json")
    ]
  })
  
  // æ¨¡æ‹Ÿåºåˆ—åŒ–è¿‡ç¨‹
  let mut serialized_headers = []
  for (key, value) in original_carrier.headers {
    serialized_headers = serialized_headers.push(key + ":" + value)
  }
  let serialized_carrier = serialized_headers.join("\n")
  
  // æ¨¡æ‹Ÿååºåˆ—åŒ–è¿‡ç¨‹
  let header_lines = serialized_carrier.split("\n")
  let mut deserialized_headers = []
  for line in header_lines {
    let kv = line.split(":")
    if kv.length() >= 2 {
      deserialized_headers = deserialized_headers.push((kv[0], kv[1]))
    }
  }
  let deserialized_carrier = TextMapCarrier({ headers: deserialized_headers })
  
  // éªŒè¯åºåˆ—åŒ–ååºåˆ—åŒ–ä¸€è‡´æ€§
  assert_eq(deserialized_carrier.headers.length(), original_carrier.headers.length())
  
  for (key, value) in original_carrier.headers {
    let mut found = false
    for (d_key, d_value) in deserialized_carrier.headers {
      if d_key == key && d_value == value {
        found = true
        break
      }
    }
    assert_true(found, "Header " + key + ":" + value + " åº”è¯¥åœ¨ååºåˆ—åŒ–ç»“æœä¸­æ‰¾åˆ°")
  }
  
  // 2. æµ‹è¯•åŒ…å«ç‰¹æ®Šå­—ç¬¦çš„TextMapCarrieråºåˆ—åŒ–ååºåˆ—åŒ–
  let special_carrier = TextMapCarrier({
    headers: [
      ("special.header!@#$%", "special.value!@#$%"),
      ("unicode.header.ä¸­æ–‡", "unicode.value.ğŸŒŸ"),
      ("empty.value", ""),
      ("colon.header:", "value:with:colons"),
      ("newline.header\n", "value\nwith\nnewlines")
    ]
  })
  
  // æ¨¡æ‹Ÿåºåˆ—åŒ–è¿‡ç¨‹ï¼ˆéœ€è¦è½¬ä¹‰ç‰¹æ®Šå­—ç¬¦ï¼‰
  let mut special_serialized_headers = []
  for (key, value) in special_carrier.headers {
    // ç®€åŒ–çš„è½¬ä¹‰å¤„ç†
    let escaped_key = key.replace(":", "\\:").replace("\n", "\\n")
    let escaped_value = value.replace(":", "\\:").replace("\n", "\\n")
    special_serialized_headers = special_serialized_headers.push(escaped_key + ":" + escaped_value)
  }
  let serialized_special_carrier = special_serialized_headers.join("\n")
  
  // æ¨¡æ‹Ÿååºåˆ—åŒ–è¿‡ç¨‹ï¼ˆéœ€è¦åè½¬ä¹‰ï¼‰
  let special_header_lines = serialized_special_carrier.split("\n")
  let mut special_deserialized_headers = []
  for line in special_header_lines {
    let kv = line.split(":")
    if kv.length() >= 2 {
      // ç®€åŒ–çš„åè½¬ä¹‰å¤„ç†
      let unescaped_key = kv[0].replace("\\:", ":").replace("\\n", "\n")
      let unescaped_value = kv[1].replace("\\:", ":").replace("\\n", "\n")
      special_deserialized_headers = special_deserialized_headers.push((unescaped_key, unescaped_value))
    }
  }
  let deserialized_special_carrier = TextMapCarrier({ headers: special_deserialized_headers })
  
  // éªŒè¯åºåˆ—åŒ–ååºåˆ—åŒ–ä¸€è‡´æ€§
  assert_eq(deserialized_special_carrier.headers.length(), special_carrier.headers.length())
  
  for (key, value) in special_carrier.headers {
    let mut found = false
    for (d_key, d_value) in deserialized_special_carrier.headers {
      if d_key == key && d_value == value {
        found = true
        break
      }
    }
    assert_true(found, "ç‰¹æ®ŠHeader " + key + ":" + value + " åº”è¯¥åœ¨ååºåˆ—åŒ–ç»“æœä¸­æ‰¾åˆ°")
  }
  
  // 3. æµ‹è¯•ç©ºTextMapCarrieråºåˆ—åŒ–ååºåˆ—åŒ–
  let empty_carrier = TextMapCarrier({ headers: [] })
  
  // æ¨¡æ‹Ÿåºåˆ—åŒ–è¿‡ç¨‹
  let serialized_empty_carrier = ""
  
  // æ¨¡æ‹Ÿååºåˆ—åŒ–è¿‡ç¨‹
  let deserialized_empty_carrier = if serialized_empty_carrier == "" {
    TextMapCarrier({ headers: [] })
  } else {
    let header_lines = serialized_empty_carrier.split("\n")
    let mut headers = []
    for line in header_lines {
      let kv = line.split(":")
      if kv.length() >= 2 {
        headers = headers.push((kv[0], kv[1]))
      }
    }
    TextMapCarrier({ headers: headers })
  }
  
  // éªŒè¯åºåˆ—åŒ–ååºåˆ—åŒ–ä¸€è‡´æ€§
  assert_eq(deserialized_empty_carrier.headers.length(), 0)
}

// æµ‹è¯•5: InstrumentationScopeåºåˆ—åŒ–ååºåˆ—åŒ–æµ‹è¯•
test "InstrumentationScopeåºåˆ—åŒ–ååºåˆ—åŒ–æµ‹è¯•" {
  // 1. æµ‹è¯•åŸºæœ¬InstrumentationScopeåºåˆ—åŒ–ååºåˆ—åŒ–
  let original_scope = InstrumentationScope({
    name: "azimuth.telemetry",
    version: Some("1.0.0"),
    schema_url: Some("https://opentelemetry.io/schemas/v1.20.0")
  })
  
  // æ¨¡æ‹Ÿåºåˆ—åŒ–è¿‡ç¨‹
  let version_str = match original_scope.version {
    Some(v) => v
    None => ""
  }
  let schema_url_str = match original_scope.schema_url {
    Some(url) => url
    None => ""
  }
  let serialized_scope = original_scope.name + "|" + version_str + "|" + schema_url_str
  
  // æ¨¡æ‹Ÿååºåˆ—åŒ–è¿‡ç¨‹
  let scope_parts = serialized_scope.split("|")
  let deserialized_version = if scope_parts[1] == "" { None } else { Some(scope_parts[1]) }
  let deserialized_schema_url = if scope_parts[2] == "" { None } else { Some(scope_parts[2]) }
  let deserialized_scope = InstrumentationScope({
    name: scope_parts[0],
    version: deserialized_version,
    schema_url: deserialized_schema_url
  })
  
  // éªŒè¯åºåˆ—åŒ–ååºåˆ—åŒ–ä¸€è‡´æ€§
  assert_eq(deserialized_scope.name, original_scope.name)
  
  match deserialized_scope.version {
    Some(v) => {
      match original_scope.version {
        Some(ov) => assert_eq(v, ov)
        None => assert_true(false, "ååºåˆ—åŒ–ç‰ˆæœ¬ä¸åº”ä¸ºSome")
      }
    }
    None => {
      match original_scope.version {
        Some(_) => assert_true(false, "ååºåˆ—åŒ–ç‰ˆæœ¬ä¸åº”ä¸ºNone")
        None => assert_true(true)
      }
    }
  }
  
  match deserialized_scope.schema_url {
    Some(url) => {
      match original_scope.schema_url {
        Some(ourl) => assert_eq(url, ourl)
        None => assert_true(false, "ååºåˆ—åŒ–schema_urlä¸åº”ä¸ºSome")
      }
    }
    None => {
      match original_scope.schema_url {
        Some(_) => assert_true(false, "ååºåˆ—åŒ–schema_urlä¸åº”ä¸ºNone")
        None => assert_true(true)
      }
    }
  }
  
  // 2. æµ‹è¯•éƒ¨åˆ†å­—æ®µçš„InstrumentationScopeåºåˆ—åŒ–ååºåˆ—åŒ–
  let partial_scope = InstrumentationScope({
    name: "partial.scope",
    version: Some("2.1.0"),
    schema_url: None
  })
  
  // æ¨¡æ‹Ÿåºåˆ—åŒ–è¿‡ç¨‹
  let partial_version_str = match partial_scope.version {
    Some(v) => v
    None => ""
  }
  let partial_schema_url_str = match partial_scope.schema_url {
    Some(url) => url
    None => ""
  }
  let serialized_partial_scope = partial_scope.name + "|" + partial_version_str + "|" + partial_schema_url_str
  
  // æ¨¡æ‹Ÿååºåˆ—åŒ–è¿‡ç¨‹
  let partial_scope_parts = serialized_partial_scope.split("|")
  let deserialized_partial_version = if partial_scope_parts[1] == "" { None } else { Some(partial_scope_parts[1]) }
  let deserialized_partial_schema_url = if partial_scope_parts[2] == "" { None } else { Some(partial_scope_parts[2]) }
  let deserialized_partial_scope = InstrumentationScope({
    name: partial_scope_parts[0],
    version: deserialized_partial_version,
    schema_url: deserialized_partial_schema_url
  })
  
  // éªŒè¯åºåˆ—åŒ–ååºåˆ—åŒ–ä¸€è‡´æ€§
  assert_eq(deserialized_partial_scope.name, partial_scope.name)
  match deserialized_partial_scope.version {
    Some(v) => assert_eq(v, "2.1.0")
    None => assert_true(false, "ç‰ˆæœ¬ä¸åº”ä¸ºNone")
  }
  match deserialized_partial_scope.schema_url {
    None => assert_true(true)
    Some(_) => assert_true(false, "Schema URLåº”ä¸ºNone")
  }
}

// æµ‹è¯•6: å¤åˆæ•°æ®ç»“æ„åºåˆ—åŒ–ååºåˆ—åŒ–æµ‹è¯•
test "å¤åˆæ•°æ®ç»“æ„åºåˆ—åŒ–ååºåˆ—åŒ–æµ‹è¯•" {
  // 1. åˆ›å»ºå¤åˆæ•°æ®ç»“æ„
  let original_context = SpanContext({
    trace_id: "12345678901234567890123456789012",
    span_id: "1234567890123456",
    sampled: true,
    trace_state: "service=test,operation=process"
  })
  
  let original_baggage = Baggage({
    entries: [
      ("user.id", "user123"),
      ("request.id", "req456"),
      ("operation.name", "data_processing")
    ]
  })
  
  let original_carrier = TextMapCarrier({
    headers: [
      ("traceparent", "00-12345678901234567890123456789012-1234567890123456-01"),
      ("tracestate", "service=test,operation=process"),
      ("baggage", "user.id=user123,request.id=req456,operation.name=data_processing"),
      ("x-request-id", "req-456"),
      ("content-type", "application/json")
    ]
  })
  
  let original_scope = InstrumentationScope({
    name: "test.telemetry",
    version: Some("1.0.0"),
    schema_url: Some("https://opentelemetry.io/schemas/v1.20.0")
  })
  
  // 2. æ¨¡æ‹Ÿå¤åˆåºåˆ—åŒ–è¿‡ç¨‹
  // åºåˆ—åŒ–SpanContext
  let serialized_context = original_context.trace_id + "|" + 
                          original_context.span_id + "|" + 
                          (if original_context.sampled { "true" } else { "false" }) + "|" + 
                          original_context.trace_state
  
  // åºåˆ—åŒ–Baggage
  let mut baggage_pairs = []
  for (key, value) in original_baggage.entries {
    baggage_pairs = baggage_pairs.push(key + "=" + value)
  }
  let serialized_baggage = baggage_pairs.join(",")
  
  // åºåˆ—åŒ–TextMapCarrier
  let mut carrier_headers = []
  for (key, value) in original_carrier.headers {
    carrier_headers = carrier_headers.push(key + ":" + value)
  }
  let serialized_carrier = carrier_headers.join("\n")
  
  // åºåˆ—åŒ–InstrumentationScope
  let scope_version = match original_scope.version {
    Some(v) => v
    None => ""
  }
  let scope_schema_url = match original_scope.schema_url {
    Some(url) => url
    None => ""
  }
  let serialized_scope = original_scope.name + "|" + scope_version + "|" + scope_schema_url
  
  // ç»„åˆæ‰€æœ‰åºåˆ—åŒ–ç»“æœ
  let serialized_complex = "SpanContext:" + serialized_context + "\n" + 
                          "Baggage:" + serialized_baggage + "\n" + 
                          "TextMapCarrier:" + serialized_carrier + "\n" + 
                          "InstrumentationScope:" + serialized_scope
  
  // 3. æ¨¡æ‹Ÿå¤åˆååºåˆ—åŒ–è¿‡ç¨‹
  let complex_sections = serialized_complex.split("\n")
  
  // ååºåˆ—åŒ–SpanContext
  let context_section = complex_sections[0]
  let context_data = context_section.split(":")[1]
  let context_parts = context_data.split("|")
  let deserialized_context = SpanContext({
    trace_id: context_parts[0],
    span_id: context_parts[1],
    sampled: context_parts[2] == "true",
    trace_state: context_parts[3]
  })
  
  // ååºåˆ—åŒ–Baggage
  let baggage_section = complex_sections[1]
  let baggage_data = baggage_section.split(":")[1]
  let baggage_pairs_deser = baggage_data.split(",")
  let mut baggage_entries = []
  for pair in baggage_pairs_deser {
    let kv = pair.split("=")
    if kv.length() >= 2 {
      baggage_entries = baggage_entries.push((kv[0], kv[1]))
    }
  }
  let deserialized_baggage = Baggage({ entries: baggage_entries })
  
  // ååºåˆ—åŒ–TextMapCarrier
  let carrier_section = complex_sections[2]
  let carrier_data = carrier_section.split(":")[1]
  let carrier_lines = carrier_data.split("\n")
  let mut carrier_headers = []
  for line in carrier_lines {
    let kv = line.split(":")
    if kv.length() >= 2 {
      carrier_headers = carrier_headers.push((kv[0], kv[1]))
    }
  }
  let deserialized_carrier = TextMapCarrier({ headers: carrier_headers })
  
  // ååºåˆ—åŒ–InstrumentationScope
  let scope_section = complex_sections[3]
  let scope_data = scope_section.split(":")[1]
  let scope_parts = scope_data.split("|")
  let deserialized_scope_version = if scope_parts[1] == "" { None } else { Some(scope_parts[1]) }
  let deserialized_scope_schema_url = if scope_parts[2] == "" { None } else { Some(scope_parts[2]) }
  let deserialized_scope = InstrumentationScope({
    name: scope_parts[0],
    version: deserialized_scope_version,
    schema_url: deserialized_scope_schema_url
  })
  
  // 4. éªŒè¯å¤åˆåºåˆ—åŒ–ååºåˆ—åŒ–ä¸€è‡´æ€§
  
  // éªŒè¯SpanContext
  assert_eq(deserialized_context.trace_id, original_context.trace_id)
  assert_eq(deserialized_context.span_id, original_context.span_id)
  assert_eq(deserialized_context.sampled, original_context.sampled)
  assert_eq(deserialized_context.trace_state, original_context.trace_state)
  
  // éªŒè¯Baggage
  assert_eq(deserialized_baggage.entries.length(), original_baggage.entries.length())
  for (key, value) in original_baggage.entries {
    let mut found = false
    for (d_key, d_value) in deserialized_baggage.entries {
      if d_key == key && d_value == value {
        found = true
        break
      }
    }
    assert_true(found, "Baggageé”®å€¼å¯¹ " + key + "=" + value + " åº”è¯¥åœ¨ååºåˆ—åŒ–ç»“æœä¸­æ‰¾åˆ°")
  }
  
  // éªŒè¯TextMapCarrier
  assert_eq(deserialized_carrier.headers.length(), original_carrier.headers.length())
  for (key, value) in original_carrier.headers {
    let mut found = false
    for (d_key, d_value) in deserialized_carrier.headers {
      if d_key == key && d_value == value {
        found = true
        break
      }
    }
    assert_true(found, "Carrier header " + key + ":" + value + " åº”è¯¥åœ¨ååºåˆ—åŒ–ç»“æœä¸­æ‰¾åˆ°")
  }
  
  // éªŒè¯InstrumentationScope
  assert_eq(deserialized_scope.name, original_scope.name)
  match deserialized_scope.version {
    Some(v) => {
      match original_scope.version {
        Some(ov) => assert_eq(v, ov)
        None => assert_true(false, "ååºåˆ—åŒ–ç‰ˆæœ¬ä¸åº”ä¸ºSome")
      }
    }
    None => {
      match original_scope.version {
        Some(_) => assert_true(false, "ååºåˆ—åŒ–ç‰ˆæœ¬ä¸åº”ä¸ºNone")
        None => assert_true(true)
      }
    }
  }
  match deserialized_scope.schema_url {
    Some(url) => {
      match original_scope.schema_url {
        Some(ourl) => assert_eq(url, ourl)
        None => assert_true(false, "ååºåˆ—åŒ–schema_urlä¸åº”ä¸ºSome")
      }
    }
    None => {
      match original_scope.schema_url {
        Some(_) => assert_true(false, "ååºåˆ—åŒ–schema_urlä¸åº”ä¸ºNone")
        None => assert_true(true)
      }
    }
  }
}