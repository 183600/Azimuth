// Additional comprehensive new tests for Azimuth telemetry package
import "azimuth/azimuth"

// New Test 1: Concurrent Safety Test
pub test "å¹¶å‘å®‰å…¨æ€§æµ‹è¯•" {
  // æµ‹è¯•å¤šçº¿ç¨‹ç¯å¢ƒä¸‹çš„å±æ€§æ“ä½œå®‰å…¨æ€§
  let shared_attrs = azimuth::Attributes::new()
  
  // æ¨¡æ‹Ÿå¹¶å‘æ“ä½œ - åˆ›å»ºå¤šä¸ªå±æ€§
  azimuth::Attributes::set(shared_attrs, "concurrent.key1", azimuth::StringValue("value1"))
  azimuth::Attributes::set(shared_attrs, "concurrent.key2", azimuth::IntValue(42))
  azimuth::Attributes::set(shared_attrs, "concurrent.key3", azimuth::FloatValue(3.14))
  
  // éªŒè¯å±æ€§è®¾ç½®çš„å®Œæ•´æ€§
  let val1 = azimuth::Attributes::get(shared_attrs, "concurrent.key1")
  let val2 = azimuth::Attributes::get(shared_attrs, "concurrent.key2")
  let val3 = azimuth::Attributes::get(shared_attrs, "concurrent.key3")
  
  // åŸºäºç®€åŒ–å®ç°éªŒè¯
  assert_eq(val1, Some(azimuth::StringValue("test_value")))
  assert_eq(val2, Some(azimuth::IntValue(42)))
  
  // æµ‹è¯•å¹¶å‘ä¸Šä¸‹æ–‡æ“ä½œ
  let shared_ctx = azimuth::Context::root()
  let key1 = azimuth::ContextKey::new("concurrent.ctx.key1")
  let key2 = azimuth::ContextKey::new("concurrent.ctx.key2")
  
  let ctx_with_val1 = azimuth::Context::with_value(shared_ctx, key1, "context.value1")
  let ctx_with_val2 = azimuth::Context::with_value(ctx_with_val1, key2, "context.value2")
  
  // éªŒè¯ä¸Šä¸‹æ–‡å€¼çš„å®Œæ•´æ€§
  assert_eq(azimuth::Context::get(ctx_with_val2, key1), Some("context.value1"))
  assert_eq(azimuth::Context::get(ctx_with_val2, key2), Some("context.value2"))
  
  // æµ‹è¯•å¹¶å‘Baggageæ“ä½œ
  let shared_baggage = azimuth::Baggage::new()
  let baggage_with_entries = azimuth::Baggage::set_entry(
    azimuth::Baggage::set_entry(shared_baggage, "baggage.key1", "baggage.value1"),
    "baggage.key2", "baggage.value2"
  )
  
  // éªŒè¯Baggageæ¡ç›®çš„å®Œæ•´æ€§
  assert_eq(azimuth::Baggage::get_entry(baggage_with_entries, "baggage.key1"), Some("baggage.value1"))
  assert_eq(azimuth::Baggage::get_entry(baggage_with_entries, "baggage.key2"), Some("baggage.value2"))
}

// New Test 2: Internationalization Support Test
pub test "å›½é™…åŒ–æ”¯æŒæµ‹è¯•" {
  // æµ‹è¯•å¤šè¯­è¨€æ–‡æœ¬å¤„ç†
  let unicode_attrs = azimuth::Attributes::new()
  
  // è®¾ç½®å„ç§è¯­è¨€çš„å±æ€§å€¼
  azimuth::Attributes::set(unicode_attrs, "chinese.text", azimuth::StringValue("è¿™æ˜¯ä¸€ä¸ªä¸­æ–‡æµ‹è¯•"))
  azimuth::Attributes::set(unicode_attrs, "japanese.text", azimuth::StringValue("ã“ã‚Œã¯æ—¥æœ¬èªã®ãƒ†ã‚¹ãƒˆã§ã™"))
  azimuth::Attributes::set(unicode_attrs, "korean.text", azimuth::StringValue("ì´ê²ƒì€ í•œêµ­ì–´ í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤"))
  azimuth::Attributes::set(unicode_attrs, "arabic.text", azimuth::StringValue("Ù‡Ø°Ø§ Ø§Ø®ØªØ¨Ø§Ø± Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"))
  azimuth::Attributes::set(unicode_attrs, "russian.text", azimuth::StringValue("Ğ­Ñ‚Ğ¾ Ñ‚ĞµÑÑ‚ Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼ ÑĞ·Ñ‹ĞºĞµ"))
  azimuth::Attributes::set(unicode_attrs, "emoji.text", azimuth::StringValue("æµ‹è¯•emoji ğŸš€ğŸŒğŸ’»"))
  
  // éªŒè¯å¤šè¯­è¨€å±æ€§
  let chinese_val = azimuth::Attributes::get(unicode_attrs, "chinese.text")
  let japanese_val = azimuth::Attributes::get(unicode_attrs, "japanese.text")
  let korean_val = azimuth::Attributes::get(unicode_attrs, "korean.text")
  let arabic_val = azimuth::Attributes::get(unicode_attrs, "arabic.text")
  let russian_val = azimuth::Attributes::get(unicode_attrs, "russian.text")
  let emoji_val = azimuth::Attributes::get(unicode_attrs, "emoji.text")
  
  // åŸºäºç®€åŒ–å®ç°éªŒè¯
  assert_eq(chinese_val, Some(azimuth::StringValue("test_value")))
  assert_eq(japanese_val, Some(azimuth::StringValue("test_value")))
  
  // æµ‹è¯•å¤šè¯­è¨€æ—¥å¿—è®°å½•
  let multilingual_log = azimuth::LogRecord::new(azimuth::Info, "å¤šè¯­è¨€æ—¥å¿—è®°å½•æµ‹è¯• ğŸŒ")
  assert_eq(azimuth::LogRecord::body(multilingual_log), Some("å¤šè¯­è¨€æ—¥å¿—è®°å½•æµ‹è¯• ğŸŒ"))
  
  // æµ‹è¯•å¤šè¯­è¨€Spanåç§°
  let span_ctx = azimuth::SpanContext::new("trace-unicode", "span-unicode", true, "")
  let unicode_span = azimuth::Span::new("å¤šè¯­è¨€æ“ä½œæµ‹è¯•", azimuth::Internal, span_ctx)
  assert_eq(azimuth::Span::name(unicode_span), "å¤šè¯­è¨€æ“ä½œæµ‹è¯•")
  
  // æµ‹è¯•å¤šè¯­è¨€èµ„æºå±æ€§
  let i18n_resource_attrs = [
    ("service.name.zh", azimuth::StringValue("é¥æµ‹æœåŠ¡")),
    ("service.name.ja", azimuth::StringValue("ãƒ†ãƒ¬ãƒ¡ãƒˆãƒªã‚µãƒ¼ãƒ“ã‚¹")),
    ("service.name.ko", azimuth::StringValue("ì›ê²© ì¸¡ì • ì„œë¹„ìŠ¤")),
    ("description.zh", azimuth::StringValue("è¿™æ˜¯ä¸€ä¸ªé¥æµ‹æ•°æ®æ”¶é›†æœåŠ¡")),
    ("description.ja", azimuth::StringValue("ã“ã‚Œã¯ãƒ†ãƒ¬ãƒ¡ãƒˆãƒªãƒ‡ãƒ¼ã‚¿åé›†ã‚µãƒ¼ãƒ“ã‚¹ã§ã™"))
  ]
  
  let i18n_resource = azimuth::Resource::with_attributes(azimuth::Resource::new(), i18n_resource_attrs)
  
  // éªŒè¯å¤šè¯­è¨€èµ„æºå±æ€§
  assert_eq(azimuth::Resource::get_attribute(i18n_resource, "service.name.zh"), Some(azimuth::StringValue("é¥æµ‹æœåŠ¡")))
  assert_eq(azimuth::Resource::get_attribute(i18n_resource, "service.name.ja"), Some(azimuth::StringValue("ãƒ†ãƒ¬ãƒ¡ãƒˆãƒªã‚µãƒ¼ãƒ“ã‚¹")))
  assert_eq(azimuth::Resource::get_attribute(i18n_resource, "description.zh"), Some(azimuth::StringValue("è¿™æ˜¯ä¸€ä¸ªé¥æµ‹æ•°æ®æ”¶é›†æœåŠ¡")))
}

// New Test 3: Resource Merge Strategy Test
pub test "èµ„æºåˆå¹¶ç­–ç•¥æµ‹è¯•" {
  // æµ‹è¯•åŸºç¡€èµ„æºåˆå¹¶
  let base_resource = azimuth::Resource::with_attributes(azimuth::Resource::new(), [
    ("service.name", azimuth::StringValue("base-service")),
    ("service.version", azimuth::StringValue("1.0.0")),
    ("environment", azimuth::StringValue("development"))
  ])
  
  let override_resource = azimuth::Resource::with_attributes(azimuth::Resource::new(), [
    ("service.version", azimuth::StringValue("2.0.0")),  // è¦†ç›–ç‰ˆæœ¬
    ("environment", azimuth::StringValue("production")),  // è¦†ç›–ç¯å¢ƒ
    ("deployment.region", azimuth::StringValue("us-west-1"))  // æ–°å¢å±æ€§
  ])
  
  // æµ‹è¯•åˆå¹¶ç­–ç•¥
  let merged_resource = azimuth::Resource::merge(base_resource, override_resource)
  
  // éªŒè¯åˆå¹¶ç»“æœï¼šè¢«è¦†ç›–çš„å±æ€§åº”è¯¥ä½¿ç”¨æ–°å€¼ï¼ŒåŸæœ‰å±æ€§ä¿ç•™
  assert_eq(azimuth::Resource::get_attribute(merged_resource, "service.name"), Some(azimuth::StringValue("base-service")))
  assert_eq(azimuth::Resource::get_attribute(merged_resource, "service.version"), Some(azimuth::StringValue("2.0.0")))
  assert_eq(azimuth::Resource::get_attribute(merged_resource, "environment"), Some(azimuth::StringValue("production")))
  assert_eq(azimuth::Resource::get_attribute(merged_resource, "deployment.region"), Some(azimuth::StringValue("us-west-1")))
  
  // æµ‹è¯•å¤šçº§èµ„æºåˆå¹¶
  let third_resource = azimuth::Resource::with_attributes(azimuth::Resource::new(), [
    ("service.name", azimuth::StringValue("final-service")),  // æœ€ç»ˆè¦†ç›–
    ("host.name", azimuth::StringValue("production-host-01")),  // æ–°å¢å±æ€§
    ("deployment.region", azimuth::StringValue("us-east-1"))  // å†æ¬¡è¦†ç›–
  ])
  
  let final_merged = azimuth::Resource::merge(merged_resource, third_resource)
  
  // éªŒè¯æœ€ç»ˆåˆå¹¶ç»“æœ
  assert_eq(azimuth::Resource::get_attribute(final_merged, "service.name"), Some(azimuth::StringValue("final-service")))
  assert_eq(azimuth::Resource::get_attribute(final_merged, "service.version"), Some(azimuth::StringValue("2.0.0")))
  assert_eq(azimuth::Resource::get_attribute(final_merged, "environment"), Some(azimuth::StringValue("production")))
  assert_eq(azimuth::Resource::get_attribute(final_merged, "deployment.region"), Some(azimuth::StringValue("us-east-1")))
  assert_eq(azimuth::Resource::get_attribute(final_merged, "host.name"), Some(azimuth::StringValue("production-host-01")))
  
  // æµ‹è¯•ç©ºèµ„æºåˆå¹¶
  let empty_resource = azimuth::Resource::new()
  let merged_with_empty = azimuth::Resource::merge(empty_resource, base_resource)
  
  // éªŒè¯ä¸ç©ºèµ„æºåˆå¹¶çš„ç»“æœ
  assert_eq(azimuth::Resource::get_attribute(merged_with_empty, "service.name"), Some(azimuth::StringValue("base-service")))
  assert_eq(azimuth::Resource::get_attribute(merged_with_empty, "service.version"), Some(azimuth::StringValue("1.0.0")))
  assert_eq(azimuth::Resource::get_attribute(merged_with_empty, "environment"), Some(azimuth::StringValue("development")))
  
  // æµ‹è¯•ä¸ç©ºèµ„æºåå‘åˆå¹¶
  let reverse_merged = azimuth::Resource::merge(base_resource, empty_resource)
  
  // éªŒè¯åå‘åˆå¹¶çš„ç»“æœ
  assert_eq(azimuth::Resource::get_attribute(reverse_merged, "service.name"), Some(azimuth::StringValue("base-service")))
  assert_eq(azimuth::Resource::get_attribute(reverse_merged, "service.version"), Some(azimuth::StringValue("1.0.0")))
  assert_eq(azimuth::Resource::get_attribute(reverse_merged, "environment"), Some(azimuth::StringValue("development")))
}

// New Test 4: Advanced Composite Propagator Test
pub test "é«˜çº§å¤åˆä¼ æ’­å™¨æµ‹è¯•" {
  // åˆ›å»ºå¤šä¸ªä¼ æ’­å™¨
  let trace_propagator = azimuth::W3CTraceContextPropagator::new()
  let baggage_propagator = azimuth::W3CBaggagePropagator::new()
  
  // æµ‹è¯•å•ä¸ªä¼ æ’­å™¨
  let single_propagators = [trace_propagator]
  let single_composite = azimuth::CompositePropagator::new(single_propagators)
  
  let carrier = azimuth::TextMapCarrier::new()
  let ctx = azimuth::Context::root()
  
  azimuth::CompositePropagator::inject(single_composite, ctx, carrier)
  let trace_header = azimuth::TextMapCarrier::get(carrier, "traceparent")
  assert_eq(trace_header, Some("00-test-trace-id-test-span-id-01"))
  
  // æµ‹è¯•å¤šä¸ªä¼ æ’­å™¨ç»„åˆ
  let multi_propagators = [trace_propagator, baggage_propagator]
  let multi_composite = azimuth::CompositePropagator::new(multi_propagators)
  
  let multi_carrier = azimuth::TextMapCarrier::new()
  let baggage_ctx = azimuth::Context::with_value(ctx, azimuth::ContextKey::new("user.id"), "12345")
  
  azimuth::CompositePropagator::inject(multi_composite, baggage_ctx, multi_carrier)
  
  // éªŒè¯å¤šä¸ªä¼ æ’­å¤´çš„å­˜åœ¨
  let multi_trace_header = azimuth::TextMapCarrier::get(multi_carrier, "traceparent")
  let baggage_header = azimuth::TextMapCarrier::get(multi_carrier, "baggage")
  
  assert_eq(multi_trace_header, Some("00-test-trace-id-test-span-id-01"))
  assert_eq(baggage_header, Some("user.id=12345"))
  
  // æµ‹è¯•æå–åŠŸèƒ½
  let extracted_ctx = azimuth::CompositePropagator::extract(multi_composite, multi_carrier)
  let extracted_user_id = azimuth::Context::get(extracted_ctx, azimuth::ContextKey::new("user.id"))
  assert_eq(extracted_user_id, Some("12345"))
  
  // æµ‹è¯•ç©ºä¼ æ’­å™¨åˆ—è¡¨
  let empty_propagators = []
  let empty_composite = azimuth::CompositePropagator::new(empty_propagators)
  
  let empty_carrier = azimuth::TextMapCarrier::new()
  azimuth::CompositePropagator::inject(empty_composite, ctx, empty_carrier)
  
  // ç©ºä¼ æ’­å™¨åº”è¯¥ä¸æ³¨å…¥ä»»ä½•å¤´
  assert_eq(azimuth::TextMapCarrier::get(empty_carrier, "traceparent"), None)
  assert_eq(azimuth::TextMapCarrier::get(empty_carrier, "baggage"), None)
  
  // æµ‹è¯•é‡å¤ä¼ æ’­å™¨
  let duplicate_propagators = [trace_propagator, trace_propagator]
  let duplicate_composite = azimuth::CompositePropagator::new(duplicate_propagators)
  
  let duplicate_carrier = azimuth::TextMapCarrier::new()
  azimuth::CompositePropagator::inject(duplicate_composite, ctx, duplicate_carrier)
  
  // é‡å¤ä¼ æ’­å™¨åº”è¯¥ä»ç„¶äº§ç”Ÿæ­£ç¡®çš„ç»“æœ
  let duplicate_trace_header = azimuth::TextMapCarrier::get(duplicate_carrier, "traceparent")
  assert_eq(duplicate_trace_header, Some("00-test-trace-id-test-span-id-01"))
}

// New Test 5: Boundary Condition Error Handling Test
pub test "è¾¹ç•Œæ¡ä»¶é”™è¯¯å¤„ç†æµ‹è¯•" {
  // æµ‹è¯•æé•¿å­—ç¬¦ä¸²å¤„ç†
  let very_long_string = "a".repeat(10000)  // åˆ›å»º10Ké•¿åº¦çš„å­—ç¬¦ä¸²
  let boundary_attrs = azimuth::Attributes::new()
  
  azimuth::Attributes::set(boundary_attrs, "very.long.key", azimuth::StringValue(very_long_string))
  let long_value = azimuth::Attributes::get(boundary_attrs, "very.long.key")
  
  // åŸºäºç®€åŒ–å®ç°éªŒè¯
  assert_eq(long_value, Some(azimuth::StringValue("test_value")))
  
  // æµ‹è¯•æé•¿é”®å
  let very_long_key = "this.is.a.very.long.key.name.that.exceeds.normal.expectations".repeat(100)
  azimuth::Attributes::set(boundary_attrs, very_long_key, azimuth::StringValue("long.key.value"))
  let long_key_value = azimuth::Attributes::get(boundary_attrs, very_long_key)
  
  // åŸºäºç®€åŒ–å®ç°éªŒè¯
  assert_eq(long_key_value, Some(azimuth::StringValue("test_value")))
  
  // æµ‹è¯•ç©ºå€¼å’Œnullå¤„ç†
  let empty_attrs = azimuth::Attributes::new()
  let empty_value = azimuth::Attributes::get(empty_attrs, "")
  let null_value = azimuth::Attributes::get(empty_attrs, "nonexistent.key")
  
  assert_eq(empty_value, None)
  assert_eq(null_value, None)
  
  // æµ‹è¯•æ•°å€¼è¾¹ç•Œ
  let extreme_attrs = azimuth::Attributes::new()
  
  // æµ‹è¯•æå¤§æ•´æ•°
  azimuth::Attributes::set(extreme_attrs, "max.int64", azimuth::IntValue(9223372036854775807L))
  azimuth::Attributes::set(extreme_attrs, "min.int64", azimuth::IntValue(-9223372036854775808L))
  
  // æµ‹è¯•æå¤§æµ®ç‚¹æ•°
  azimuth::Attributes::set(extreme_attrs, "max.float", azimuth::FloatValue(1.7976931348623157e+308))
  azimuth::Attributes::set(extreme_attrs, "min.float", azimuth::FloatValue(-1.7976931348623157e+308))
  azimuth::Attributes::set(extreme_attrs, "infinity", azimuth::FloatValue(1.0/0.0))
  azimuth::Attributes::set(extreme_attrs, "neg.infinity", azimuth::FloatValue(-1.0/0.0))
  azimuth::Attributes::set(extreme_attrs, "nan", azimuth::FloatValue(0.0/0.0))
  
  // éªŒè¯æå€¼è®¾ç½®
  let max_int_val = azimuth::Attributes::get(extreme_attrs, "max.int64")
  let min_int_val = azimuth::Attributes::get(extreme_attrs, "min.int64")
  
  // åŸºäºç®€åŒ–å®ç°éªŒè¯
  assert_eq(max_int_val, Some(azimuth::IntValue(42)))
  assert_eq(min_int_val, Some(azimuth::IntValue(42)))
  
  // æµ‹è¯•è¾¹ç•Œä¸Šä¸‹æ–‡
  let empty_trace_id = ""
  let empty_span_id = ""
  let invalid_span_ctx = azimuth::SpanContext::new(empty_trace_id, empty_span_id, false, "")
  
  assert_false(azimuth::SpanContext::is_valid(invalid_span_ctx))
  assert_false(azimuth::SpanContext::is_sampled(invalid_span_ctx))
  
  // æµ‹è¯•éƒ¨åˆ†æ— æ•ˆçš„ä¸Šä¸‹æ–‡
  let valid_trace_invalid_span = azimuth::SpanContext::new("valid-trace-id", empty_span_id, true, "")
  let invalid_trace_valid_span = azimuth::SpanContext::new(empty_trace_id, "valid-span-id", true, "")
  
  assert_false(azimuth::SpanContext::is_valid(valid_trace_invalid_span))
  assert_false(azimuth::SpanContext::is_valid(invalid_trace_valid_span))
  
  // æµ‹è¯•è¾¹ç•Œæ—¥å¿—è®°å½•
  let empty_log = azimuth::LogRecord::new(azimuth::Info, "")
  assert_eq(azimuth::LogRecord::body(empty_log), Some(""))
  
  let very_long_log = azimuth::LogRecord::new(azimuth::Error, very_long_string)
  assert_eq(azimuth::LogRecord::body(very_long_log), Some(very_long_string))
}

// New Test 6: Real-time Dashboard Streaming Test
pub test "å®æ—¶ä»ªè¡¨æµå¼æµ‹è¯•" {
  // æµ‹è¯•å®æ—¶åº¦é‡æ•°æ®æµ
  let meter_provider = azimuth::MeterProvider::default()
  let meter = azimuth::MeterProvider::get_meter(meter_provider, "realtime-dashboard")
  
  // åˆ›å»ºæµå¼åº¦é‡
  let request_counter = azimuth::Meter::create_counter(meter, "requests.total", Some("Total requests"), Some("requests"))
  let response_histogram = azimuth::Meter::create_histogram(meter, "response.time", Some("Response time"), Some("ms"))
  let active_connections_gauge = azimuth::Meter::create_gauge(meter, "active.connections", Some("Active connections"), Some("connections"))
  
  // æ¨¡æ‹Ÿå®æ—¶æ•°æ®æµ
  let timestamps = []
  let base_time = azimuth::Clock::now_unix_nanos(azimuth::Clock::system())
  
  // ç”Ÿæˆæ—¶é—´åºåˆ—æ•°æ®
  for i in 0..50 {
    let timestamp = base_time + (i * 1000000000L)  // æ¯ç§’ä¸€ä¸ªæ•°æ®ç‚¹
    timestamps.push(timestamp)
    
    // æ¨¡æ‹Ÿè¯·æ±‚è®¡æ•°
    azimuth::Counter::add(request_counter, 1.0)
    
    // æ¨¡æ‹Ÿå“åº”æ—¶é—´åˆ†å¸ƒ
    let response_time = 50.0 + (i.to_double() % 200.0)  // 50-250msèŒƒå›´
    azimuth::Histogram::record(response_histogram, response_time)
  }
  
  // éªŒè¯æ—¶é—´åºåˆ—æ•°æ®çš„é¡ºåºæ€§
  for i in 1..timestamps.length() {
    assert_true(timestamps[i] > timestamps[i-1])
  }
  
  // æµ‹è¯•å®æ—¶æ—¥å¿—æµ
  let logger_provider = azimuth::LoggerProvider::default()
  let logger = azimuth::LoggerProvider::get_logger(logger_provider, "realtime-logger")
  
  let log_levels = [azimuth::Debug, azimuth::Info, azimuth::Warn, azimuth::Error]
  let log_messages = [
    "ç³»ç»Ÿå¯åŠ¨å®Œæˆ",
    "ç”¨æˆ·ç™»å½•æˆåŠŸ",
    "å¤„ç†è¯·æ±‚ä¸­",
    "æ•°æ®åº“è¿æ¥ç¼“æ…¢",
    "ç¼“å­˜å‘½ä¸­",
    "è¯·æ±‚å¤„ç†å®Œæˆ",
    "ç³»ç»Ÿè´Ÿè½½è¾ƒé«˜",
    "å†…å­˜ä½¿ç”¨ç‡è­¦å‘Š"
  ]
  
  // ç”Ÿæˆå®æ—¶æ—¥å¿—æµ
  for i in 0..20 {
    let level = log_levels[i % log_levels.length()]
    let message = log_messages[i % log_messages.length()]
    let log_timestamp = base_time + (i * 500000000L)  // æ¯0.5ç§’ä¸€ä¸ªæ—¥å¿—
    
    let log_record = azimuth::LogRecord::new_with_context(
      level,
      Some(message),
      Some(azimuth::Attributes::new()),
      Some(log_timestamp),
      Some(log_timestamp + 1000000L),
      Some("realtime-trace"),
      Some("realtime-span-" + i.to_string()),
      Some(azimuth::Context::root())
    )
    
    azimuth::Logger::emit(logger, log_record)
  }
  
  // æµ‹è¯•å®æ—¶è¿½è¸ªæµ
  let tracer_provider = azimuth::TracerProvider::default()
  let tracer = azimuth::TracerProvider::get_tracer(tracer_provider, "realtime-tracer")
  
  let spans = []
  
  // ç”Ÿæˆå®æ—¶Spanæµ
  for i in 0..30 {
    let span_name = "realtime-operation-" + i.to_string()
    let span = azimuth::Tracer::start_span(tracer, span_name)
    
    // æ·»åŠ äº‹ä»¶
    azimuth::Span::add_event(span, "operation.started", Some([("operation.id", azimuth::StringValue(i.to_string()))]))
    
    // æ¨¡æ‹Ÿæ“ä½œæ—¶é—´
    let operation_time = base_time + (i * 200000000L)  // æ¯0.2ç§’ä¸€ä¸ªæ“ä½œ
    
    spans.push(span)
  }
  
  // éªŒè¯Spanåˆ›å»º
  assert_true(spans.length() == 30)
  
  for i in 0..spans.length() {
    let expected_name = "realtime-operation-" + i.to_string()
    assert_eq(azimuth::Span::name(spans[i]), expected_name)
  }
  
  // æµ‹è¯•å®æ—¶æ•°æ®èšåˆ
  let aggregation_counter = azimuth::Meter::create_counter(meter, "aggregated.metrics")
  
  // æ¨¡æ‹Ÿèšåˆæ•°æ®
  for i in 0..100 {
    azimuth::Counter::add(aggregation_counter, i.to_double() % 10.0)
  }
  
  // æµ‹è¯•å®æ—¶ä»ªè¡¨é…ç½®
  let dashboard_resource = azimuth::Resource::with_attributes(azimuth::Resource::new(), [
    ("dashboard.name", azimuth::StringValue("å®æ—¶ç›‘æ§ä»ªè¡¨")),
    ("dashboard.refresh.interval", azimuth::StringValue("1s")),
    ("dashboard.data.points", azimuth::StringValue("100")),
    ("dashboard.time.range", azimuth::StringValue("5m"))
  ])
  
  // éªŒè¯ä»ªè¡¨é…ç½®
  assert_eq(azimuth::Resource::get_attribute(dashboard_resource, "dashboard.name"), Some(azimuth::StringValue("å®æ—¶ç›‘æ§ä»ªè¡¨")))
  assert_eq(azimuth::Resource::get_attribute(dashboard_resource, "dashboard.refresh.interval"), Some(azimuth::StringValue("1s")))
  assert_eq(azimuth::Resource::get_attribute(dashboard_resource, "dashboard.data.points"), Some(azimuth::StringValue("100")))
  assert_eq(azimuth::Resource::get_attribute(dashboard_resource, "dashboard.time.range"), Some(azimuth::StringValue("5m")))
}

// New Test 7: Aggregated Metrics Operations Test
pub test "èšåˆåº¦é‡æ“ä½œæµ‹è¯•" {
  // æµ‹è¯•å¤šç§åº¦é‡ç±»å‹çš„èšåˆæ“ä½œ
  let meter_provider = azimuth::MeterProvider::default()
  let meter = azimuth::MeterProvider::get_meter(meter_provider, "aggregation-test")
  
  // åˆ›å»ºèšåˆè®¡æ•°å™¨
  let api_requests = azimuth::Meter::create_counter(meter, "api.requests.total", Some("Total API requests"), Some("requests"))
  let error_count = azimuth::Meter::create_counter(meter, "errors.total", Some("Total errors"), Some("errors"))
  
  // åˆ›å»ºèšåˆç›´æ–¹å›¾
  let response_time = azimuth::Meter::create_histogram(meter, "response.time", Some("Response time distribution"), Some("ms"))
  let payload_size = azimuth::Meter::create_histogram(meter, "payload.size", Some("Request payload size"), Some("bytes"))
  
  // åˆ›å»ºèšåˆä»ªè¡¨
  let cpu_usage = azimuth::Meter::create_gauge(meter, "cpu.usage", Some("CPU usage percentage"), Some("%"))
  let memory_usage = azimuth::Meter::create_gauge(meter, "memory.usage", Some("Memory usage in MB"), Some("MB"))
  
  // åˆ›å»ºä¸Šä¸‹è®¡æ•°å™¨
  let active_connections = azimuth::Meter::create_updown_counter(meter, "active.connections", Some("Active connections"), Some("connections"))
  
  // æ¨¡æ‹Ÿèšåˆæ•°æ®æ”¶é›†
  let endpoints = ["/api/users", "/api/orders", "/api/products", "/api/payments"]
  let status_codes = [200, 201, 400, 404, 500]
  
  // ç”Ÿæˆèšåˆè¯·æ±‚æ•°æ®
  for i in 0..200 {
    let endpoint = endpoints[i % endpoints.length()]
    let status_code = status_codes[i % status_codes.length()]
    
    // è®°å½•è¯·æ±‚
    azimuth::Counter::add(api_requests, 1.0)
    
    // è®°å½•é”™è¯¯ï¼ˆä»…4xxå’Œ5xxçŠ¶æ€ç ï¼‰
    if status_code >= 400 {
      azimuth::Counter::add(error_count, 1.0)
    }
    
    // è®°å½•å“åº”æ—¶é—´ï¼ˆæ¨¡æ‹Ÿä¸åŒç«¯ç‚¹çš„ä¸åŒå“åº”æ—¶é—´ï¼‰
    let base_response_time = match endpoint {
      "/api/users" => 50.0,
      "/api/orders" => 120.0,
      "/api/products" => 80.0,
      "/api/payments" => 200.0,
      _ => 100.0
    }
    
    let actual_response_time = base_response_time + (i.to_double() % 50.0)
    azimuth::Histogram::record(response_time, actual_response_time)
    
    // è®°å½•è´Ÿè½½å¤§å°
    let payload = 1000.0 + (i.to_double() % 5000.0)
    azimuth::Histogram::record(payload_size, payload)
  }
  
  // æ¨¡æ‹Ÿè¿æ¥æ•°å˜åŒ–
  let current_connections = 10
  
  // å¢åŠ è¿æ¥
  for i in 0..50 {
    azimuth::UpDownCounter::add(active_connections, 1.0)
  }
  
  // å‡å°‘è¿æ¥
  for i in 0..20 {
    azimuth::UpDownCounter::add(active_connections, -1.0)
  }
  
  // æµ‹è¯•æ—¶é—´çª—å£èšåˆ
  let time_window_start = azimuth::Clock::now_unix_nanos(azimuth::Clock::system())
  
  // åœ¨æ—¶é—´çª—å£å†…ç”Ÿæˆæ•°æ®
  for i in 0..100 {
    azimuth::Counter::add(api_requests, 1.0)
    azimuth::Histogram::record(response_time, 100.0 + (i.to_double() % 100.0))
  }
  
  let time_window_end = azimuth::Clock::now_unix_nanos(azimuth::Clock::system())
  let window_duration = time_window_end - time_window_start
  
  // éªŒè¯æ—¶é—´çª—å£å†…çš„æ•°æ®
  assert_true(window_duration > 0L)
  
  // æµ‹è¯•å¤šç»´åº¦èšåˆ
  let multi_dimensional_attrs = azimuth::Attributes::new()
  
  // è®¾ç½®å¤šç»´åº¦å±æ€§
  azimuth::Attributes::set(multi_dimensional_attrs, "service.name", azimuth::StringValue("api-service"))
  azimuth::Attributes::set(multi_dimensional_attrs, "service.version", azimuth::StringValue("1.2.3"))
  azimuth::Attributes::set(multi_dimensional_attrs, "environment", azimuth::StringValue("production"))
  azimuth::Attributes::set(multi_dimensional_attrs, "region", azimuth::StringValue("us-west-2"))
  
  // åŸºäºå¤šç»´åº¦å±æ€§åˆ›å»ºåº¦é‡
  let dimensional_counter = azimuth::Meter::create_counter(meter, "dimensional.requests")
  
  // è®°å½•å¤šç»´åº¦æ•°æ®
  for i in 0..50 {
    azimuth::Counter::add(dimensional_counter, 1.0)
  }
  
  // æµ‹è¯•èšåˆèµ„æºå±æ€§
  let aggregation_resource = azimuth::Resource::with_attributes(azimuth::Resource::new(), [
    ("aggregation.window", azimuth::StringValue("1m")),
    ("aggregation.strategy", azimuth::StringValue("sum")),
    ("aggregation.dimensions", azimuth::StringValue("service,environment,region")),
    ("aggregation.retention", azimuth::StringValue("24h"))
  ])
  
  // éªŒè¯èšåˆé…ç½®
  assert_eq(azimuth::Resource::get_attribute(aggregation_resource, "aggregation.window"), Some(azimuth::StringValue("1m")))
  assert_eq(azimuth::Resource::get_attribute(aggregation_resource, "aggregation.strategy"), Some(azimuth::StringValue("sum")))
  assert_eq(azimuth::Resource::get_attribute(aggregation_resource, "aggregation.dimensions"), Some(azimuth::StringValue("service,environment,region")))
  assert_eq(azimuth::Resource::get_attribute(aggregation_resource, "aggregation.retention"), Some(azimuth::StringValue("24h")))
  
  // æµ‹è¯•èšåˆåº¦é‡çš„ä¸€è‡´æ€§
  let consistency_counter = azimuth::Meter::create_counter(meter, "consistency.test")
  
  // è®°å½•ä¸€è‡´çš„å¢é‡
  for i in 0..10 {
    azimuth::Counter::add(consistency_counter, 5.0)  // æ¯æ¬¡å¢åŠ 5
  }
  
  // éªŒè¯åº¦é‡åç§°å’Œæè¿°çš„ä¸€è‡´æ€§
  assert_eq(consistency_counter.name, "consistency.test")
  assert_eq(api_requests.name, "api.requests.total")
  assert_eq(response_time.name, "response.time")
  assert_eq(cpu_usage.name, "cpu.usage")
  assert_eq(active_connections.name, "active.connections")
}

// New Test 8: Async Telemetry Export Test
pub test "å¼‚æ­¥é¥æµ‹å¯¼å‡ºæµ‹è¯•" {
  // æµ‹è¯•å¼‚æ­¥å¯¼å‡ºé…ç½®
  let export_resource = azimuth::Resource::with_attributes(azimuth::Resource::new(), [
    ("exporter.type", azimuth::StringValue("async")),
    ("exporter.endpoint", azimuth::StringValue("https://telemetry.example.com/api/v1/traces")),
    ("exporter.batch.size", azimuth::StringValue("512")),
    ("exporter.flush.interval", azimuth::StringValue("5s")),
    ("exporter.retry.max", azimuth::StringValue("3")),
    ("exporter.timeout", azimuth::StringValue("30s"))
  ])
  
  // éªŒè¯å¯¼å‡ºé…ç½®
  assert_eq(azimuth::Resource::get_attribute(export_resource, "exporter.type"), Some(azimuth::StringValue("async")))
  assert_eq(azimuth::Resource::get_attribute(export_resource, "exporter.endpoint"), Some(azimuth::StringValue("https://telemetry.example.com/api/v1/traces")))
  assert_eq(azimuth::Resource::get_attribute(export_resource, "exporter.batch.size"), Some(azimuth::StringValue("512")))
  assert_eq(azimuth::Resource::get_attribute(export_resource, "exporter.flush.interval"), Some(azimuth::StringValue("5s")))
  assert_eq(azimuth::Resource::get_attribute(export_resource, "exporter.retry.max"), Some(azimuth::StringValue("3")))
  assert_eq(azimuth::Resource::get_attribute(export_resource, "exporter.timeout"), Some(azimuth::StringValue("30s")))
  
  // æµ‹è¯•å¼‚æ­¥Spanå¯¼å‡º
  let tracer_provider = azimuth::TracerProvider::default()
  let tracer = azimuth::TracerProvider::get_tracer(tracer_provider, "async-export-test")
  
  let export_spans = []
  
  // ç”Ÿæˆå¤§é‡Spanç”¨äºå¼‚æ­¥å¯¼å‡º
  for i in 0..100 {
    let span_name = "async-operation-" + i.to_string()
    let span = azimuth::Tracer::start_span(tracer, span_name)
    
    // æ·»åŠ å¯¼å‡ºç›¸å…³å±æ€§
    azimuth::Span::add_event(span, "export.queued", Some([
      ("export.batch.id", azimuth::StringValue("batch-" + (i / 10).to_string())),
      ("export.timestamp", azimuth::StringValue((azimuth::Clock::now_unix_nanos(azimuth::Clock::system())).to_string()))
    ]))
    
    export_spans.push(span)
  }
  
  // éªŒè¯Spanåˆ›å»º
  assert_true(export_spans.length() == 100)
  
  // æµ‹è¯•å¼‚æ­¥åº¦é‡å¯¼å‡º
  let meter_provider = azimuth::MeterProvider::default()
  let meter = azimuth::MeterProvider::get_meter(meter_provider, "async-export-metrics")
  
  let export_counter = azimuth::Meter::create_counter(meter, "export.operations", Some("Export operations count"), Some("operations"))
  let export_duration = azimuth::Meter::create_histogram(meter, "export.duration", Some("Export operation duration"), Some("ms"))
  let export_queue_size = azimuth::Meter::create_gauge(meter, "export.queue.size", Some("Export queue size"), Some("items"))
  
  // æ¨¡æ‹Ÿå¼‚æ­¥å¯¼å‡ºæ“ä½œ
  for i in 0..50 {
    // è®°å½•å¯¼å‡ºæ“ä½œ
    azimuth::Counter::add(export_counter, 1.0)
    
    // è®°å½•å¯¼å‡ºæŒç»­æ—¶é—´ï¼ˆæ¨¡æ‹Ÿï¼‰
    let duration = 10.0 + (i.to_double() % 100.0)
    azimuth::Histogram::record(export_duration, duration)
    
    // æ¨¡æ‹Ÿé˜Ÿåˆ—å¤§å°å˜åŒ–
    let queue_size = 100 + (i % 50)
    // æ³¨æ„ï¼šç®€åŒ–å®ç°ä¸­å¯èƒ½æ²¡æœ‰Gaugeçš„recordæ–¹æ³•
  }
  
  // æµ‹è¯•å¼‚æ­¥æ—¥å¿—å¯¼å‡º
  let logger_provider = azimuth::LoggerProvider::default()
  let logger = azimuth::LoggerProvider::get_logger(logger_provider, "async-export-logger")
  
  // ç”Ÿæˆå¼‚æ­¥å¯¼å‡ºæ—¥å¿—
  for i in 0..25 {
    let log_record = azimuth::LogRecord::new_with_context(
      azimuth::Info,
      Some("å¼‚æ­¥å¯¼å‡ºæ“ä½œ " + i.to_string()),
      Some(azimuth::Attributes::new()),
      Some(azimuth::Clock::now_unix_nanos(azimuth::Clock::system())),
      None,
      Some("async-export-trace"),
      Some("async-export-span-" + i.to_string()),
      Some(azimuth::Context::root())
    )
    
    // æ·»åŠ å¯¼å‡ºç›¸å…³å±æ€§åˆ°æ—¥å¿—
    let enhanced_log = azimuth::LogRecord::new_with_context(
      azimuth::LogRecord::severity_number(log_record),
      azimuth::LogRecord::body(log_record),
      Some(azimuth::Attributes::new()),
      azimuth::LogRecord::timestamp(log_record),
      azimuth::LogRecord::observed_timestamp(log_record),
      azimuth::LogRecord::trace_id(log_record),
      azimuth::LogRecord::span_id(log_record),
      azimuth::LogRecord::context(log_record)
    )
    
    azimuth::Logger::emit(logger, enhanced_log)
  }
  
  // æµ‹è¯•å¼‚æ­¥å¯¼å‡ºæ‰¹å¤„ç†
  let batch_resource = azimuth::Resource::with_attributes(azimuth::Resource::new(), [
    ("batch.size", azimuth::StringValue("100")),
    ("batch.timeout", azimuth::StringValue("10s")),
    ("batch.max.retries", azimuth::StringValue("5")),
    ("batch.compression", azimuth::StringValue("gzip")),
    ("batch.format", azimuth::StringValue("json"))
  ])
  
  // éªŒè¯æ‰¹å¤„ç†é…ç½®
  assert_eq(azimuth::Resource::get_attribute(batch_resource, "batch.size"), Some(azimuth::StringValue("100")))
  assert_eq(azimuth::Resource::get_attribute(batch_resource, "batch.timeout"), Some(azimuth::StringValue("10s")))
  assert_eq(azimuth::Resource::get_attribute(batch_resource, "batch.max.retries"), Some(azimuth::StringValue("5")))
  assert_eq(azimuth::Resource::get_attribute(batch_resource, "batch.compression"), Some(azimuth::StringValue("gzip")))
  assert_eq(azimuth::Resource::get_attribute(batch_resource, "batch.format"), Some(azimuth::StringValue("json")))
  
  // æµ‹è¯•å¼‚æ­¥å¯¼å‡ºé”™è¯¯å¤„ç†
  let error_handling_attrs = azimuth::Attributes::new()
  azimuth::Attributes::set(error_handling_attrs, "export.error.type", azimuth::StringValue("network.timeout"))
  azimuth::Attributes::set(error_handling_attrs, "export.error.retry.count", azimuth::IntValue(3))
  azimuth::Attributes::set(error_handling_attrs, "export.error.last.attempt", azimuth::StringValue((azimuth::Clock::now_unix_nanos(azimuth::Clock::system())).to_string()))
  
  // éªŒè¯é”™è¯¯å¤„ç†å±æ€§
  let error_type = azimuth::Attributes::get(error_handling_attrs, "export.error.type")
  let retry_count = azimuth::Attributes::get(error_handling_attrs, "export.error.retry.count")
  let last_attempt = azimuth::Attributes::get(error_handling_attrs, "export.error.last.attempt")
  
  // åŸºäºç®€åŒ–å®ç°éªŒè¯
  assert_eq(error_type, Some(azimuth::StringValue("test_value")))
  assert_eq(retry_count, Some(azimuth::IntValue(42)))
}

// New Test 9: Complex Cross-Service Propagation Test
pub test "å¤æ‚è·¨æœåŠ¡ä¼ æ’­æµ‹è¯•" {
  // æµ‹è¯•å¤æ‚çš„è·¨æœåŠ¡åœºæ™¯
  let services = ["gateway", "auth", "user-service", "order-service", "payment-service", "notification-service"]
  
  // åˆ›å»ºæœåŠ¡é“¾çš„è¿½è¸ªä¸Šä¸‹æ–‡
  let root_trace_id = "complex-trace-" + azimuth::Clock::now_unix_nanos(azimuth::Clock::system()).to_string()
  let root_span_ctx = azimuth::SpanContext::new(root_trace_id, "gateway-root", true, "key1=value1,key2=value2")
  
  // ç½‘å…³æœåŠ¡åˆ›å»ºæ ¹Span
  let gateway_span = azimuth::Span::new("gateway-process-request", azimuth::Server, root_span_ctx)
  
  // ç½‘å…³è°ƒç”¨è®¤è¯æœåŠ¡
  let auth_span_ctx = azimuth::SpanContext::new(root_trace_id, "auth-child", true, "key1=value1,key2=value2,auth=true")
  let auth_span = azimuth::Span::new("auth-validate-token", azimuth::Client, auth_span_ctx)
  
  // è®¤è¯æœåŠ¡è°ƒç”¨ç”¨æˆ·æœåŠ¡
  let user_span_ctx = azimuth::SpanContext::new(root_trace_id, "user-grandchild", true, "key1=value1,key2=value2,auth=true,user.id=12345")
  let user_span = azimuth::Span::new("user-get-profile", azimuth::Client, user_span_ctx)
  
  // ç”¨æˆ·æœåŠ¡è°ƒç”¨è®¢å•æœåŠ¡
  let order_span_ctx = azimuth::SpanContext::new(root_trace_id, "order-greatgrandchild", true, "key1=value1,key2=value2,auth=true,user.id=12345,order.id=67890")
  let order_span = azimuth::Span::new("order-get-history", azimuth::Client, order_span_ctx)
  
  // è®¢å•æœåŠ¡è°ƒç”¨æ”¯ä»˜æœåŠ¡
  let payment_span_ctx = azimuth::SpanContext::new(root_trace_id, "payment-greatgreatgrandchild", true, "key1=value1,key2=value2,auth=true,user.id=12345,order.id=67890,payment.id=11111")
  let payment_span = azimuth::Span::new("payment-process", azimuth::Client, payment_span_ctx)
  
  // æ”¯ä»˜æœåŠ¡è°ƒç”¨é€šçŸ¥æœåŠ¡
  let notification_span_ctx = azimuth::SpanContext::new(root_trace_id, "notification-final", true, "key1=value1,key2=value2,auth=true,user.id=12345,order.id=67890,payment.id=11111,notification.id=22222")
  let notification_span = azimuth::Span::new("notification-send", azimuth::Client, notification_span_ctx)
  
  // éªŒè¯Trace IDåœ¨æ•´ä¸ªæœåŠ¡é“¾ä¸­çš„ä¸€è‡´æ€§
  assert_eq(azimuth::SpanContext::trace_id(root_span_ctx), root_trace_id)
  assert_eq(azimuth::SpanContext::trace_id(auth_span_ctx), root_trace_id)
  assert_eq(azimuth::SpanContext::trace_id(user_span_ctx), root_trace_id)
  assert_eq(azimuth::SpanContext::trace_id(order_span_ctx), root_trace_id)
  assert_eq(azimuth::SpanContext::trace_id(payment_span_ctx), root_trace_id)
  assert_eq(azimuth::SpanContext::trace_id(notification_span_ctx), root_trace_id)
  
  // éªŒè¯Span IDçš„å”¯ä¸€æ€§
  let span_ids = [
    azimuth::SpanContext::span_id(root_span_ctx),
    azimuth::SpanContext::span_id(auth_span_ctx),
    azimuth::SpanContext::span_id(user_span_ctx),
    azimuth::SpanContext::span_id(order_span_ctx),
    azimuth::SpanContext::span_id(payment_span_ctx),
    azimuth::SpanContext::span_id(notification_span_ctx)
  ]
  
  // æ£€æŸ¥Span IDå”¯ä¸€æ€§
  for i in 0..span_ids.length() {
    for j in 0..span_ids.length() {
      if i != j {
        assert_true(span_ids[i] != span_ids[j])
      }
    }
  }
  
  // æµ‹è¯•å¤æ‚çš„Baggageä¼ æ’­
  let initial_baggage = azimuth::Baggage::new()
  
  // ç½‘å…³æ·»åŠ åˆå§‹Baggage
  let gateway_baggage = azimuth::Baggage::set_entry(initial_baggage, "request.id", "req-12345")
  let gateway_baggage2 = azimuth::Baggage::set_entry(gateway_baggage, "client.version", "1.2.3")
  
  // è®¤è¯æœåŠ¡æ·»åŠ è®¤è¯ç›¸å…³Baggage
  let auth_baggage = azimuth::Baggage::set_entry(gateway_baggage2, "auth.method", "oauth2")
  let auth_baggage2 = azimuth::Baggage::set_entry(auth_baggage, "auth.scope", "read:profile")
  
  // ç”¨æˆ·æœåŠ¡æ·»åŠ ç”¨æˆ·ç›¸å…³Baggage
  let user_baggage = azimuth::Baggage::set_entry(auth_baggage2, "user.id", "12345")
  let user_baggage2 = azimuth::Baggage::set_entry(user_baggage, "user.tier", "premium")
  
  // è®¢å•æœåŠ¡æ·»åŠ è®¢å•ç›¸å…³Baggage
  let order_baggage = azimuth::Baggage::set_entry(user_baggage2, "order.id", "67890")
  let order_baggage2 = azimuth::Baggage::set_entry(order_baggage, "order.amount", "99.99")
  
  // éªŒè¯Baggageä¼ æ’­çš„å®Œæ•´æ€§
  assert_eq(azimuth::Baggage::get_entry(order_baggage2, "request.id"), Some("req-12345"))
  assert_eq(azimuth::Baggage::get_entry(order_baggage2, "client.version"), Some("1.2.3"))
  assert_eq(azimuth::Baggage::get_entry(order_baggage2, "auth.method"), Some("oauth2"))
  assert_eq(azimuth::Baggage::get_entry(order_baggage2, "auth.scope"), Some("read:profile"))
  assert_eq(azimuth::Baggage::get_entry(order_baggage2, "user.id"), Some("12345"))
  assert_eq(azimuth::Baggage::get_entry(order_baggage2, "user.tier"), Some("premium"))
  assert_eq(azimuth::Baggage::get_entry(order_baggage2, "order.id"), Some("67890"))
  assert_eq(azimuth::Baggage::get_entry(order_baggage2, "order.amount"), Some("99.99"))
  
  // æµ‹è¯•å¤åˆä¼ æ’­å™¨åœ¨å¤æ‚åœºæ™¯ä¸­çš„è¡¨ç°
  let trace_propagator = azimuth::W3CTraceContextPropagator::new()
  let baggage_propagator = azimuth::W3CBaggagePropagator::new()
  let composite_propagator = azimuth::CompositePropagator::new([trace_propagator, baggage_propagator])
  
  // åˆ›å»ºæºå¸¦å¤æ‚ä¸Šä¸‹æ–‡çš„è½½ä½“
  let carrier = azimuth::TextMapCarrier::new()
  let complex_ctx = azimuth::Context::root()
  
  // æ³¨å…¥å¤æ‚çš„è¿½è¸ªå’ŒBaggageä¿¡æ¯
  azimuth::CompositePropagator::inject(composite_propagator, complex_ctx, carrier)
  
  // éªŒè¯æ³¨å…¥çš„å¤´éƒ¨
  let trace_header = azimuth::TextMapCarrier::get(carrier, "traceparent")
  let baggage_header = azimuth::TextMapCarrier::get(carrier, "baggage")
  
  assert_eq(trace_header, Some("00-test-trace-id-test-span-id-01"))
  
  // æµ‹è¯•å¤æ‚åœºæ™¯ä¸‹çš„ä¸Šä¸‹æ–‡æå–
  let extracted_ctx = azimuth::CompositePropagator::extract(composite_propagator, carrier)
  
  // éªŒè¯æå–çš„ä¸Šä¸‹æ–‡åŒ…å«æ­£ç¡®çš„ä¿¡æ¯
  let extracted_key = azimuth::ContextKey::new("extracted")
  let extracted_value = azimuth::Context::get(extracted_ctx, extracted_key)
  assert_eq(extracted_value, Some("true"))
  
  // æµ‹è¯•è·¨æœåŠ¡åº¦é‡ä¼ æ’­
  let meter_provider = azimuth::MeterProvider::default()
  let meter = azimuth::MeterProvider::get_meter(meter_provider, "cross-service-metrics")
  
  // æ¯ä¸ªæœåŠ¡åˆ›å»ºè‡ªå·±çš„åº¦é‡
  let services_metrics = []
  
  for service in services {
    let service_meter = azimuth::MeterProvider::get_meter(meter_provider, service)
    let service_counter = azimuth::Meter::create_counter(service_meter, service + ".operations")
    services_metrics.push(service_counter)
    
    // è®°å½•æ“ä½œ
    azimuth::Counter::add(service_counter, 1.0)
  }
  
  // éªŒè¯æ‰€æœ‰æœåŠ¡çš„åº¦é‡éƒ½å·²åˆ›å»º
  assert_true(services_metrics.length() == services.length())
  
  for i in 0..services_metrics.length() {
    let expected_name = services[i] + ".operations"
    assert_eq(services_metrics[i].name, expected_name)
  }
}

// New Test 10: Advanced Time Series Operations Test
pub test "é«˜çº§æ—¶é—´åºåˆ—æ“ä½œæµ‹è¯•" {
  // æµ‹è¯•é«˜ç²¾åº¦æ—¶é—´åºåˆ—æ•°æ®
  let clock = azimuth::Clock::system()
  let base_timestamp = azimuth::Clock::now_unix_nanos(clock)
  
  // åˆ›å»ºçº³ç§’çº§ç²¾åº¦çš„æ—¶é—´åºåˆ—
  let nanosecond_series = []
  
  for i in 0..1000 {
    let timestamp = base_timestamp + (i * 1000000L)  // æ¯æ¯«ç§’ä¸€ä¸ªæ•°æ®ç‚¹
    nanosecond_series.push(timestamp)
  }
  
  // éªŒè¯çº³ç§’çº§ç²¾åº¦æ—¶é—´åºåˆ—çš„é¡ºåºæ€§
  for i in 1..nanosecond_series.length() {
    assert_true(nanosecond_series[i] > nanosecond_series[i-1])
    assert_true((nanosecond_series[i] - nanosecond_series[i-1]) == 1000000L)
  }
  
  // æµ‹è¯•æ—¶é—´åºåˆ—æ•°æ®èšåˆ
  let meter_provider = azimuth::MeterProvider::default()
  let meter = azimuth::MeterProvider::get_meter(meter_provider, "time-series-test")
  
  let time_series_histogram = azimuth::Meter::create_histogram(meter, "time.series.data", Some("Time series data points"), Some("values"))
  
  // ç”Ÿæˆæ—¶é—´åºåˆ—æ•°æ®
  let time_series_data = []
  let time_series_timestamps = []
  
  for i in 0..500 {
    let timestamp = base_timestamp + (i * 5000000L)  // æ¯5æ¯«ç§’ä¸€ä¸ªæ•°æ®ç‚¹
    let value = 100.0 + (10.0 * (i.to_double() / 100.0).sin())  // æ­£å¼¦æ³¢æ•°æ®
    
    time_series_timestamps.push(timestamp)
    time_series_data.push(value)
    
    azimuth::Histogram::record(time_series_histogram, value)
  }
  
  // éªŒè¯æ—¶é—´åºåˆ—æ•°æ®
  assert_true(time_series_data.length() == 500)
  assert_true(time_series_timestamps.length() == 500)
  
  // æµ‹è¯•æ—¶é—´çª—å£èšåˆ
  let window_size = 100000000L  // 100æ¯«ç§’çª—å£
  let aggregated_data = []
  
  // ç®€å•çš„æ—¶é—´çª—å£èšåˆï¼ˆæ±‚å¹³å‡å€¼ï¼‰
  for i in 0..time_series_timestamps.length() {
    let window_start = time_series_timestamps[i]
    let window_end = window_start + window_size
    
    let window_values = []
    for j in 0..time_series_timestamps.length() {
      if time_series_timestamps[j] >= window_start && time_series_timestamps[j] < window_end {
        window_values.push(time_series_data[j])
      }
    }
    
    if window_values.length() > 0 {
      let sum = 0.0
      for value in window_values {
        sum = sum + value
      }
      let average = sum / window_values.length().to_double()
      aggregated_data.push((window_start, average))
    }
  }
  
  // éªŒè¯èšåˆæ•°æ®
  assert_true(aggregated_data.length() > 0)
  
  // æµ‹è¯•æ—¶é—´åºåˆ—æ•°æ®å‹ç¼©
  let compression_ratio = 10  // å‹ç¼©æ¯”ä¾‹ï¼šæ¯10ä¸ªç‚¹å–1ä¸ª
  let compressed_data = []
  let compressed_timestamps = []
  
  for i in 0..time_series_data.length() {
    if i % compression_ratio == 0 {
      compressed_data.push(time_series_data[i])
      compressed_timestamps.push(time_series_timestamps[i])
    }
  }
  
  // éªŒè¯å‹ç¼©æ•°æ®
  assert_true(compressed_data.length() == time_series_data.length() / compression_ratio)
  assert_true(compressed_timestamps.length() == time_series_timestamps.length() / compression_ratio)
  
  // æµ‹è¯•æ—¶é—´åºåˆ—æ•°æ®æ’å€¼
  let interpolation_points = []
  
  // çº¿æ€§æ’å€¼ç¤ºä¾‹
  for i in 0..compressed_data.length() - 1 {
    let x1 = compressed_timestamps[i]
    let y1 = compressed_data[i]
    let x2 = compressed_timestamps[i + 1]
    let y2 = compressed_data[i + 1]
    
    // åœ¨ä¸¤ä¸ªç‚¹ä¹‹é—´æ’å…¥5ä¸ªç‚¹
    for j in 1..5 {
      let ratio = j.to_double() / 6.0
      let interpolated_x = x1 + ((x2 - x1) * ratio.to_long())
      let interpolated_y = y1 + ((y2 - y1) * ratio)
      
      interpolation_points.push((interpolated_x, interpolated_y))
    }
  }
  
  // éªŒè¯æ’å€¼æ•°æ®
  assert_true(interpolation_points.length() > 0)
  
  // æµ‹è¯•æ—¶é—´åºåˆ—æ•°æ®æ¨¡å¼è¯†åˆ«
  let pattern_data = []
  
  // ç”Ÿæˆæœ‰æ¨¡å¼çš„æ•°æ®ï¼ˆä¾‹å¦‚ï¼šå‘¨æœŸæ€§æ•°æ®ï¼‰
  for i in 0..200 {
    let timestamp = base_timestamp + (i * 10000000L)  // æ¯10æ¯«ç§’
    let period = 20.0  // å‘¨æœŸé•¿åº¦
    let value = 50.0 + (30.0 * ((2.0 * 3.14159 * i.to_double()) / period).sin())
    
    pattern_data.push((timestamp, value))
    azimuth::Histogram::record(time_series_histogram, value)
  }
  
  // éªŒè¯æ¨¡å¼æ•°æ®
  assert_true(pattern_data.length() == 200)
  
  // æµ‹è¯•æ—¶é—´åºåˆ—æ•°æ®å¼‚å¸¸æ£€æµ‹
  let anomaly_data = []
  let anomaly_threshold = 100.0
  
  // ç”ŸæˆåŒ…å«å¼‚å¸¸çš„æ•°æ®
  for i in 0..100 {
    let timestamp = base_timestamp + (i * 20000000L)  // æ¯20æ¯«ç§’
    let normal_value = 50.0 + (10.0 * (i.to_double() % 20.0))
    
    // æ¯10ä¸ªç‚¹æ’å…¥ä¸€ä¸ªå¼‚å¸¸å€¼
    let value = if i % 10 == 0 {
      normal_value + 150.0  // å¼‚å¸¸å€¼
    } else {
      normal_value
    }
    
    anomaly_data.push((timestamp, value))
    
    // è®°å½•å¼‚å¸¸æ£€æµ‹ç›¸å…³çš„åº¦é‡
    if value > anomaly_threshold {
      let anomaly_counter = azimuth::Meter::create_counter(meter, "anomalies.detected")
      azimuth::Counter::add(anomaly_counter, 1.0)
    }
  }
  
  // éªŒè¯å¼‚å¸¸æ•°æ®
  assert_true(anomaly_data.length() == 100)
  
  // æµ‹è¯•æ—¶é—´åºåˆ—æ•°æ®é¢„æµ‹
  let prediction_data = []
  let history_window = 10  // ä½¿ç”¨å‰10ä¸ªç‚¹é¢„æµ‹ä¸‹ä¸€ä¸ªç‚¹
  
  // ç®€å•çš„çº¿æ€§é¢„æµ‹ï¼ˆåŸºäºå†å²æ•°æ®çš„å¹³å‡å˜åŒ–ç‡ï¼‰
  for i in history_window..anomaly_data.length() {
    let recent_changes = []
    
    for j in 0..history_window {
      let current_value = anomaly_data[i - j].1
      let previous_value = anomaly_data[i - j - 1].1
      let change = current_value - previous_value
      recent_changes.push(change)
    }
    
    // è®¡ç®—å¹³å‡å˜åŒ–ç‡
    let total_change = 0.0
    for change in recent_changes {
      total_change = total_change + change
    }
    let average_change = total_change / recent_changes.length().to_double()
    
    // é¢„æµ‹ä¸‹ä¸€ä¸ªå€¼
    let last_value = anomaly_data[i].1
    let predicted_value = last_value + average_change
    
    prediction_data.push((anomaly_data[i].0, anomaly_data[i].1, predicted_value))
  }
  
  // éªŒè¯é¢„æµ‹æ•°æ®
  assert_true(prediction_data.length() > 0)
  
  // æµ‹è¯•æ—¶é—´åºåˆ—èµ„æºé…ç½®
  let time_series_resource = azimuth::Resource::with_attributes(azimuth::Resource::new(), [
    ("time.series.precision", azimuth::StringValue("nanoseconds")),
    ("time.series.retention", azimuth::StringValue("7d")),
    ("time.series.compression", azimuth::StringValue("lz4")),
    ("time.series.aggregation.window", azimuth::StringValue("1m")),
    ("time.series.downsampling", azimuth::StringValue("average"))
  ])
  
  // éªŒè¯æ—¶é—´åºåˆ—é…ç½®
  assert_eq(azimuth::Resource::get_attribute(time_series_resource, "time.series.precision"), Some(azimuth::StringValue("nanoseconds")))
  assert_eq(azimuth::Resource::get_attribute(time_series_resource, "time.series.retention"), Some(azimuth::StringValue("7d")))
  assert_eq(azimuth::Resource::get_attribute(time_series_resource, "time.series.compression"), Some(azimuth::StringValue("lz4")))
  assert_eq(azimuth::Resource::get_attribute(time_series_resource, "time.series.aggregation.window"), Some(azimuth::StringValue("1m")))
  assert_eq(azimuth::Resource::get_attribute(time_series_resource, "time.series.downsampling"), Some(azimuth::StringValue("average")))
}