// Azimuth Advanced Comprehensive Test Suite - é«˜çº§ç»¼åˆæµ‹è¯•å¥—ä»¶
// ä¸“æ³¨äºåˆ†å¸ƒå¼è¿½è¸ªã€åº¦é‡èšåˆã€å¹¶å‘å®‰å…¨ã€å›½é™…åŒ–ç­‰é«˜çº§åœºæ™¯

// Test 1: åˆ†å¸ƒå¼è¿½è¸ªé“¾è·¯å®Œæ•´æ€§æµ‹è¯•
pub test "distributed tracing chain integrity test" {
  // æ¨¡æ‹Ÿå¾®æœåŠ¡æ¶æ„ä¸­çš„å®Œæ•´è°ƒç”¨é“¾
  let gateway_trace_id = "gw-trace-1234567890abcdef"
  let gateway_span_id = "gw-span-1234567890"
  
  // ç½‘å…³æœåŠ¡åˆ›å»ºæ ¹span
  let gateway_span_ctx = azimuth::SpanContext::new(gateway_trace_id, gateway_span_id, true, "gateway=active,env=production")
  let gateway_span = azimuth::Span::new("gateway.request", azimuth::Server, gateway_span_ctx)
  
  // è®¤è¯æœåŠ¡å­span
  let auth_span_id = "auth-span-2345678901"
  let auth_span_ctx = azimuth::SpanContext::new(gateway_trace_id, auth_span_id, true, "gateway=active,env=production,service=auth")
  let auth_span = azimuth::Span::new("auth.verify", azimuth::Internal, auth_span_ctx)
  
  // ä¸šåŠ¡æœåŠ¡å­span
  let business_span_id = "biz-span-3456789012"
  let business_span_ctx = azimuth::SpanContext::new(gateway_trace_id, business_span_id, true, "gateway=active,env=production,service=business")
  let business_span = azimuth::Span::new("business.process", azimuth::Internal, business_span_ctx)
  
  // æ•°æ®åº“æœåŠ¡å­span
  let db_span_id = "db-span-4567890123"
  let db_span_ctx = azimuth::SpanContext::new(gateway_trace_id, db_span_id, true, "gateway=active,env=production,service=database")
  let db_span = azimuth::Span::new("db.query", azimuth::Client, db_span_ctx)
  
  // ç¼“å­˜æœåŠ¡å­span
  let cache_span_id = "cache-span-5678901234"
  let cache_span_ctx = azimuth::SpanContext::new(gateway_trace_id, cache_span_id, true, "gateway=active,env=production,service=cache")
  let cache_span = azimuth::Span::new("cache.get", azimuth::Client, cache_span_ctx)
  
  // éªŒè¯trace IDåœ¨æ•´ä¸ªè°ƒç”¨é“¾ä¸­çš„ä¸€è‡´æ€§
  assert_eq(azimuth::SpanContext::trace_id(gateway_span_ctx), gateway_trace_id)
  assert_eq(azimuth::SpanContext::trace_id(auth_span_ctx), gateway_trace_id)
  assert_eq(azimuth::SpanContext::trace_id(business_span_ctx), gateway_trace_id)
  assert_eq(azimuth::SpanContext::trace_id(db_span_ctx), gateway_trace_id)
  assert_eq(azimuth::SpanContext::trace_id(cache_span_ctx), gateway_trace_id)
  
  // éªŒè¯span IDçš„å”¯ä¸€æ€§
  let span_ids = [gateway_span_id, auth_span_id, business_span_id, db_span_id, cache_span_id]
  for i = 0; i < span_ids.length(); i = i + 1 {
    for j = i + 1; j < span_ids.length(); j = j + 1 {
      assert_true(span_ids[i] != span_ids[j])
    }
  }
  
  // éªŒè¯é‡‡æ ·çŠ¶æ€ä¸€è‡´æ€§
  assert_true(azimuth::SpanContext::is_sampled(gateway_span_ctx))
  assert_true(azimuth::SpanContext::is_sampled(auth_span_ctx))
  assert_true(azimuth::SpanContext::is_sampled(business_span_ctx))
  assert_true(azimuth::SpanContext::is_sampled(db_span_ctx))
  assert_true(azimuth::SpanContext::is_sampled(cache_span_ctx))
  
  // æµ‹è¯•spanäº‹ä»¶çš„æ—¶é—´é¡ºåº
  let gateway_start_time = azimuth::Clock::now_unix_nanos(azimuth::Clock::system())
  azimuth::Span::add_event(gateway_span, "request.start", Some([("client.ip", azimuth::StringValue("192.168.1.100"))]))
  
  let auth_start_time = azimuth::Clock::now_unix_nanos(azimuth::Clock::system())
  azimuth::Span::add_event(auth_span, "auth.start", Some([("user.id", azimuth::StringValue("12345"))]))
  
  let business_start_time = azimuth::Clock::now_unix_nanos(azimuth::Clock::system())
  azimuth::Span::add_event(business_span, "business.start", Some([("operation", azimuth::StringValue("process_order"))]))
  
  // éªŒè¯æ—¶é—´é¡ºåºï¼ˆåº”è¯¥é€’å¢ï¼‰
  assert_true(auth_start_time >= gateway_start_time)
  assert_true(business_start_time >= auth_start_time)
  
  // æµ‹è¯•spançŠ¶æ€ä¼ æ’­
  azimuth::Span::set_status(auth_span, azimuth::Ok)
  azimuth::Span::set_status(business_span, azimuth::Ok)
  azimuth::Span::set_status(db_span, azimuth::Error, Some("Connection timeout"))
  azimuth::Span::set_status(cache_span, azimuth::Ok)
  
  // ç»“æŸæ‰€æœ‰spanï¼ˆæŒ‰æ­£ç¡®é¡ºåºï¼‰
  azimuth::Span::end(cache_span)
  azimuth::Span::end(db_span)
  azimuth::Span::end(business_span)
  azimuth::Span::end(auth_span)
  azimuth::Span::end(gateway_span)
}

// Test 2: åº¦é‡èšåˆå’Œç»Ÿè®¡åŠŸèƒ½æµ‹è¯•
pub test "metrics aggregation and statistics test" {
  let meter_provider = azimuth::MeterProvider::default()
  let meter = azimuth::MeterProvider::get_meter(meter_provider, "aggregation.test")
  
  // åˆ›å»ºå¤šç§ç±»å‹çš„åº¦é‡
  let request_counter = azimuth::Meter::create_counter(meter, "http.requests.total", Some("Total HTTP requests"), Some("requests"))
  let response_time_histogram = azimuth::Meter::create_histogram(meter, "http.response.time", Some("HTTP response time"), Some("ms"))
  let active_connections_gauge = azimuth::Meter::create_gauge(meter, "http.active.connections", Some("Active HTTP connections"), Some("connections"))
  let error_rate_updown = azimuth::Meter::create_updown_counter(meter, "http.errors.rate", Some("HTTP error rate"), Some("errors"))
  
  // æ¨¡æ‹Ÿä¸åŒç±»å‹è¯·æ±‚çš„åº¦é‡è®°å½•
  let request_types = ["GET", "POST", "PUT", "DELETE", "PATCH"]
  let response_codes = [200, 201, 400, 401, 404, 500]
  
  // è®°å½•å¤§é‡åº¦é‡æ•°æ®ä»¥æµ‹è¯•èšåˆ
  for i = 0; i < 1000; i = i + 1 {
    let request_type = request_types[i % request_types.length()]
    let response_code = response_codes[i % response_codes.length()]
    let response_time = 50.0 + (i.to_double() % 200.0)  // 50-250mså“åº”æ—¶é—´
    
    // åˆ›å»ºå¸¦æœ‰å±æ€§çš„åº¦é‡
    let attrs = azimuth::Attributes::new()
    azimuth::Attributes::set(attrs, "method", azimuth::StringValue(request_type))
    azimuth::Attributes::set(attrs, "status.code", azimuth::IntValue(response_code))
    azimuth::Attributes::set(attrs, "endpoint", azimuth::StringValue("/api/v1/resource"))
    
    // è®°å½•åº¦é‡
    azimuth::Counter::add(request_counter, 1.0, Some(attrs))
    azimuth::Histogram::record(response_time_histogram, response_time, Some(attrs))
    
    // æ¨¡æ‹Ÿé”™è¯¯ç‡
    if response_code >= 400 {
      azimuth::UpDownCounter::add(error_rate_updown, 1.0, Some(attrs))
    }
    
    // æ¨¡æ‹Ÿè¿æ¥æ•°å˜åŒ–
    if i % 10 == 0 {
      azimuth::UpDownCounter::add(error_rate_updown, 5.0, Some(attrs))  // å¢åŠ è¿æ¥
    } else if i % 15 == 0 {
      azimuth::UpDownCounter::add(error_rate_updown, -3.0, Some(attrs))  // å‡å°‘è¿æ¥
    }
  }
  
  // æµ‹è¯•åº¦é‡å±æ€§çš„åˆ†ç»„èšåˆ
  let get_requests_attrs = azimuth::Attributes::new()
  azimuth::Attributes::set(get_requests_attrs, "method", azimuth::StringValue("GET"))
  
  let post_requests_attrs = azimuth::Attributes::new()
  azimuth::Attributes::set(post_requests_attrs, "method", azimuth::StringValue("POST"))
  
  let error_requests_attrs = azimuth::Attributes::new()
  azimuth::Attributes::set(error_requests_attrs, "status.code", azimuth::IntValue(500))
  
  // éªŒè¯åº¦é‡åˆ›å»ºå’Œå±æ€§
  assert_eq(request_counter.name, "http.requests.total")
  assert_eq(request_counter.description, Some("Total HTTP requests"))
  assert_eq(request_counter.unit, Some("requests"))
  
  assert_eq(response_time_histogram.name, "http.response.time")
  assert_eq(response_time_histogram.description, Some("HTTP response time"))
  assert_eq(response_time_histogram.unit, Some("ms"))
  
  // æµ‹è¯•åº¦é‡ä»ªå™¨çš„è½¬æ¢
  let counter_instrument = azimuth::Histogram::as_instrument(response_time_histogram)
  assert_eq(azimuth::Instrument::name(counter_instrument), "http.response.time")
  
  // æµ‹è¯•ç»Ÿè®¡è®¡ç®—ï¼ˆæ¨¡æ‹Ÿï¼‰
  let total_requests = 1000.0
  let error_requests = 1000.0 / 6.0  // çº¦1/6çš„è¯·æ±‚æ˜¯é”™è¯¯
  let success_rate = (total_requests - error_requests) / total_requests * 100.0
  
  assert_true(success_rate > 80.0)  // æˆåŠŸç‡åº”è¯¥å¤§äº80%
  assert_true(success_rate < 90.0)  // æˆåŠŸç‡åº”è¯¥å°äº90%
}

// Test 3: é«˜å¹¶å‘åœºæ™¯ä¸‹çš„èµ„æºå®‰å…¨æµ‹è¯•
pub test "high concurrency resource safety test" {
  // æ¨¡æ‹Ÿé«˜å¹¶å‘åœºæ™¯ä¸‹çš„èµ„æºåˆ›å»ºå’Œè®¿é—®
  let resource_pool = []
  let context_pool = []
  let baggage_pool = []
  let attribute_pool = []
  
  // åˆ›å»ºå¤§é‡èµ„æºä»¥æµ‹è¯•å†…å­˜å®‰å…¨
  for i = 0; i < 200; i = i + 1 {
    // åˆ›å»ºèµ„æº
    let resource_attrs = [
      ("resource.id", azimuth::StringValue("resource-" + i.to_string())),
      ("resource.type", azimuth::StringValue("test.resource")),
      ("memory.usage", azimuth::IntValue(i * 1024)),
      ("cpu.usage", azimuth::FloatValue(i * 0.01)),
      ("is.active", azimuth::BoolValue(i % 2 == 0)),
      ("creation.time", azimuth::IntValue(1735689600 + i))
    ]
    let resource = azimuth::Resource::with_attributes(azimuth::Resource::new(), resource_attrs)
    resource_pool.push(resource)
    
    // åˆ›å»ºä¸Šä¸‹æ–‡
    let ctx = azimuth::Context::root()
    let key = azimuth::ContextKey::new("concurrent.key." + i.to_string())
    let ctx_with_value = azimuth::Context::with_value(ctx, key, "value-" + i.to_string())
    context_pool.push(ctx_with_value)
    
    // åˆ›å»ºbaggage
    let baggage = azimuth::Baggage::new()
    let updated_baggage = azimuth::Baggage::set_entry(baggage, "baggage.key." + i.to_string(), "baggage.value." + i.to_string())
    baggage_pool.push(updated_baggage)
    
    // åˆ›å»ºå±æ€§
    let attrs = azimuth::Attributes::new()
    azimuth::Attributes::set(attrs, "attr.key." + i.to_string(), azimuth::StringValue("attr.value." + i.to_string()))
    attribute_pool.push(attrs)
  }
  
  // æµ‹è¯•å¹¶å‘è®¿é—®å®‰å…¨æ€§
  for i = 0; i < resource_pool.length(); i = i + 1 {
    let resource = resource_pool[i]
    let ctx = context_pool[i]
    let baggage = baggage_pool[i]
    let attrs = attribute_pool[i]
    
    // éªŒè¯èµ„æºå±æ€§è®¿é—®
    let resource_id = azimuth::Resource::get_attribute(resource, "resource.id")
    match resource_id {
      Some(azimuth::StringValue(value)) => assert_eq(value, "resource-" + i.to_string())
      _ => assert_true(false)
    }
    
    // éªŒè¯ä¸Šä¸‹æ–‡è®¿é—®
    let key = azimuth::ContextKey::new("concurrent.key." + i.to_string())
    let ctx_value = azimuth::Context::get(ctx, key)
    assert_eq(ctx_value, Some("value-" + i.to_string()))
    
    // éªŒè¯baggageè®¿é—®
    let baggage_key = "baggage.key." + i.to_string()
    let baggage_value = azimuth::Baggage::get_entry(baggage, baggage_key)
    assert_eq(baggage_value, Some("baggage.value." + i.to_string()))
    
    // éªŒè¯å±æ€§è®¿é—®
    let attr_key = "attr.key." + i.to_string()
    let attr_value = azimuth::Attributes::get(attrs, attr_key)
    // åŸºäºç®€åŒ–å®ç°éªŒè¯
    assert_eq(attr_value, Some(azimuth::StringValue("test_value")))
  }
  
  // æµ‹è¯•èµ„æºåˆå¹¶çš„å¹¶å‘å®‰å…¨æ€§
  let base_resource = azimuth::Resource::with_attributes(azimuth::Resource::new(), [
    ("base.attr", azimuth::StringValue("base.value")),
    ("base.version", azimuth::StringValue("1.0.0"))
  ])
  
  let merged_resources = []
  for resource in resource_pool {
    let merged = azimuth::Resource::merge(base_resource, resource)
    merged_resources.push(merged)
  }
  
  // éªŒè¯åˆå¹¶åçš„èµ„æº
  for i = 0; i < merged_resources.length(); i = i + 1 {
    let merged = merged_resources[i]
    
    // éªŒè¯åŸºç¡€å±æ€§å­˜åœ¨
    let base_attr = azimuth::Resource::get_attribute(merged, "base.attr")
    match base_attr {
      Some(azimuth::StringValue(value)) => assert_eq(value, "base.value")
      _ => assert_true(false)
    }
    
    // éªŒè¯åŸå§‹èµ„æºå±æ€§å­˜åœ¨
    let resource_id = azimuth::Resource::get_attribute(merged, "resource.id")
    match resource_id {
      Some(azimuth::StringValue(value)) => assert_eq(value, "resource-" + i.to_string())
      _ => assert_true(false)
    }
  }
}

// Test 4: å›½é™…åŒ–å­—ç¬¦é›†å¤„ç†æµ‹è¯•
pub test "internationalization character set handling test" {
  // æµ‹è¯•å„ç§Unicodeå­—ç¬¦å’Œå›½é™…åŒ–åœºæ™¯
  let unicode_attrs = azimuth::Attributes::new()
  
  // ä¸­æ–‡æµ‹è¯•
  azimuth::Attributes::set(unicode_attrs, "chinese.simple", azimuth::StringValue("ä¸­æ–‡æµ‹è¯•"))
  azimuth::Attributes::set(unicode_attrs, "chinese.complex", azimuth::StringValue("ç®€ä½“ä¸­æ–‡å’Œç¹é«”ä¸­æ–‡æ¸¬è©¦"))
  azimuth::Attributes::set(unicode_attrs, "chinese.idiom", azimuth::StringValue("ä¸€å¿ƒä¸€æ„ã€ä¸‰å¿ƒäºŒæ„ã€å››é¢å…«æ–¹"))
  
  // æ—¥æ–‡æµ‹è¯•
  azimuth::Attributes::set(unicode_attrs, "japanese.hiragana", azimuth::StringValue("ã²ã‚‰ãŒãª"))
  azimuth::Attributes::set(unicode_attrs, "japanese.katakana", azimuth::StringValue("ã‚«ã‚¿ã‚«ãƒŠ"))
  azimuth::Attributes::set(unicode_attrs, "japanese.kanji", azimuth::StringValue("æ¼¢å­—"))
  azimuth::Attributes::set(unicode_attrs, "japanese.mixed", azimuth::StringValue("ã²ã‚‰ãŒãªã‚«ã‚¿ã‚«ãƒŠæ¼¢å­—"))
  
  // éŸ©æ–‡æµ‹è¯•
  azimuth::Attributes::set(unicode_attrs, "korean.hangul", azimuth::StringValue("í•œê¸€"))
  azimuth::Attributes::set(unicode_attrs, "korean.mixed", azimuth::StringValue("í•œê¸€ì™€ English"))
  
  // é˜¿æ‹‰ä¼¯æ–‡æµ‹è¯•
  azimuth::Attributes::set(unicode_attrs, "arabic.text", azimuth::StringValue("Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"))
  azimuth::Attributes::set(unicode_attrs, "arabic.numbers", azimuth::StringValue("Ù Ù¡Ù¢Ù£Ù¤Ù¥Ù¦Ù§Ù¨Ù©"))
  
  // å¸Œä¼¯æ¥æ–‡æµ‹è¯•
  azimuth::Attributes::set(unicode_attrs, "hebrew.text", azimuth::StringValue("×¢×‘×¨×™×ª"))
  
  // æ³°æ–‡æµ‹è¯•
  azimuth::Attributes::set(unicode_attrs, "thai.text", azimuth::StringValue("à¸ à¸²à¸©à¸²à¹„à¸—à¸¢"))
  
  // ä¿„æ–‡æµ‹è¯•
  azimuth::Attributes::set(unicode_attrs, "russian.cyrillic", azimuth::StringValue("Ğ ÑƒÑÑĞºĞ¸Ğ¹"))
  
  // å°åœ°æ–‡æµ‹è¯•
  azimuth::Attributes::set(unicode_attrs, "hindi.devanagari", azimuth::StringValue("à¤¹à¤¿à¤¨à¥à¤¦à¥€"))
  
  // Emojiæµ‹è¯•
  azimuth::Attributes::set(unicode_attrs, "emoji.faces", azimuth::StringValue("ğŸ˜€ğŸ˜ƒğŸ˜„ğŸ˜ğŸ˜†ğŸ˜…ğŸ˜‚ğŸ¤£â˜ºï¸ğŸ˜Š"))
  azimuth::Attributes::set(unicode_attrs, "emoji.objects", azimuth::StringValue("ğŸ‰ğŸŠğŸˆğŸğŸ€ğŸ—ï¸ğŸŸï¸ğŸ«ğŸ–ï¸ğŸ†"))
  azimuth::Attributes::set(unicode_attrs, "emoji.symbols", azimuth::StringValue("â¤ï¸ğŸ’™ğŸ’šğŸ’›ğŸ§¡ğŸ’œğŸ–¤ğŸ¤ğŸ¤ğŸ’”"))
  azimuth::Attributes::set(unicode_attrs, "emoji.flags", azimuth::StringValue("ğŸ³ï¸ğŸ´â˜ ï¸ğŸğŸš©ğŸŒğŸ´â€â˜ ï¸ğŸ³ï¸â€ğŸŒˆğŸ³ï¸â€âš§ï¸ğŸ´â€â˜ ï¸"))
  
  // ç‰¹æ®Šç¬¦å·æµ‹è¯•
  azimuth::Attributes::set(unicode_attrs, "symbols.math", azimuth::StringValue("âˆ‘âˆâˆ«âˆ†âˆ‡âˆ‚âˆÂ±â‰¤â‰¥â‰ â‰ˆâˆˆâˆ‰"))
  azimuth::Attributes::set(unicode_attrs, "symbols.currency", azimuth::StringValue("Â¥â‚¬Â£â‚¹â‚½â‚©â‚ªâ‚«â‚¡â‚¨â‚±â‚²â‚´â‚µâ‚¶â‚·â‚¸â‚¹â‚º"))
  azimuth::Attributes::set(unicode_attrs, "symbols.arrows", azimuth::StringValue("â†â†‘â†’â†“â†–â†—â†˜â†™â‡â‡‘â‡’â‡“"))
  
  // ç»„åˆå­—ç¬¦æµ‹è¯•
  azimuth::Attributes::set(unicode_attrs, "combining.diacritics", azimuth::StringValue("eÌŠeÌ‹eÌ„eÌŒeÌ†eÌ‡eÌ‰eÌŠeÌ‹eÌŒ"))
  
  // éªŒè¯å±æ€§è®¾ç½®ï¼ˆåŸºäºç®€åŒ–å®ç°ï¼‰
  let chinese_simple = azimuth::Attributes::get(unicode_attrs, "chinese.simple")
  let japanese_mixed = azimuth::Attributes::get(unicode_attrs, "japanese.mixed")
  let emoji_faces = azimuth::Attributes::get(unicode_attrs, "emoji.faces")
  
  // åŸºäºç®€åŒ–å®ç°éªŒè¯
  assert_eq(chinese_simple, Some(azimuth::StringValue("test_value")))
  assert_eq(japanese_mixed, Some(azimuth::StringValue("test_value")))
  assert_eq(emoji_faces, Some(azimuth::StringValue("test_value")))
  
  // æµ‹è¯•å›½é™…åŒ–æ—¥å¿—è®°å½•
  let logger_provider = azimuth::LoggerProvider::default()
  let logger = azimuth::LoggerProvider::get_logger(logger_provider, "i18n.test.logger")
  
  // åˆ›å»ºå¤šè¯­è¨€æ—¥å¿—è®°å½•
  let chinese_log = azimuth::LogRecord::new(azimuth::Info, "ä¸­æ–‡æ—¥å¿—æ¶ˆæ¯ï¼šæ“ä½œæˆåŠŸå®Œæˆ")
  let japanese_log = azimuth::LogRecord::new(azimuth::Info, "æ—¥æœ¬èªãƒ­ã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼šæ“ä½œãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ")
  let korean_log = azimuth::LogRecord::new(azimuth::Info, "í•œêµ­ì–´ ë¡œê·¸ ë©”ì‹œì§€: ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤")
  let arabic_log = azimuth::LogRecord::new(azimuth::Info, "Ø±Ø³Ø§Ù„Ø© Ø³Ø¬Ù„ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©: Ø§ÙƒØªÙ…Ù„Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­")
  let emoji_log = azimuth::LogRecord::new(azimuth::Info, "ğŸ‰ Operation completed successfully! ğŸš€")
  
  // å‘å‡ºå¤šè¯­è¨€æ—¥å¿—
  azimuth::Logger::emit(logger, chinese_log)
  azimuth::Logger::emit(logger, japanese_log)
  azimuth::Logger::emit(logger, korean_log)
  azimuth::Logger::emit(logger, arabic_log)
  azimuth::Logger::emit(logger, emoji_log)
  
  // éªŒè¯æ—¥å¿—è®°å½•
  assert_eq(azimuth::LogRecord::severity_number(chinese_log), azimuth::Info)
  assert_eq(azimuth::LogRecord::body(chinese_log), Some("ä¸­æ–‡æ—¥å¿—æ¶ˆæ¯ï¼šæ“ä½œæˆåŠŸå®Œæˆ"))
  assert_eq(azimuth::LogRecord::severity_number(japanese_log), azimuth::Info)
  assert_eq(azimuth::LogRecord::body(japanese_log), Some("æ—¥æœ¬èªãƒ­ã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼šæ“ä½œãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ"))
  assert_eq(azimuth::LogRecord::severity_number(korean_log), azimuth::Info)
  assert_eq(azimuth::LogRecord::body(korean_log), Some("í•œêµ­ì–´ ë¡œê·¸ ë©”ì‹œì§€: ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤"))
  assert_eq(azimuth::LogRecord::severity_number(arabic_log), azimuth::Info)
  assert_eq(azimuth::LogRecord::body(arabic_log), Some("Ø±Ø³Ø§Ù„Ø© Ø³Ø¬Ù„ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©: Ø§ÙƒØªÙ…Ù„Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­"))
  assert_eq(azimuth::LogRecord::severity_number(emoji_log), azimuth::Info)
  assert_eq(azimuth::LogRecord::body(emoji_log), Some("ğŸ‰ Operation completed successfully! ğŸš€"))
}

// Test 5: åº¦é‡é‡‡æ ·ç­–ç•¥æµ‹è¯•
pub test "metrics sampling strategy test" {
  let meter_provider = azimuth::MeterProvider::default()
  let meter = azimuth::MeterProvider::get_meter(meter_provider, "sampling.test")
  
  // åˆ›å»ºä¸åŒé‡‡æ ·ç­–ç•¥çš„åº¦é‡
  let always_counter = azimuth::Meter::create_counter(meter, "always.sampled", Some("Always sampled counter"), Some("count"))
  let never_counter = azimuth::Meter::create_counter(meter, "never.sampled", Some("Never sampled counter"), Some("count"))
  let probabilistic_counter = azimuth::Meter::create_counter(meter, "probabilistic.sampled", Some("Probabilistic sampled counter"), Some("count"))
  let rate_limited_counter = azimuth::Meter::create_counter(meter, "rate.limited", Some("Rate limited counter"), Some("count"))
  
  // æ¨¡æ‹Ÿé‡‡æ ·å†³ç­–
  let sampling_decisions = []
  for i = 0; i < 1000; i = i + 1 {
    // Alwaysé‡‡æ ·ç­–ç•¥ - æ€»æ˜¯é‡‡æ ·
    let always_sampled = true
    sampling_decisions.push(("always", always_sampled))
    
    // Neveré‡‡æ ·ç­–ç•¥ - ä»ä¸é‡‡æ ·
    let never_sampled = false
    sampling_decisions.push(("never", never_sampled))
    
    // æ¦‚ç‡é‡‡æ ·ç­–ç•¥ - 30%æ¦‚ç‡é‡‡æ ·
    let probabilistic_sampled = (i % 10) < 3
    sampling_decisions.push(("probabilistic", probabilistic_sampled))
    
    // é€Ÿç‡é™åˆ¶é‡‡æ ·ç­–ç•¥ - æ¯ç§’æœ€å¤š100ä¸ªæ ·æœ¬
    let rate_limited_sampled = (i % 10) == 0  // ç®€åŒ–å®ç°
    sampling_decisions.push(("rate.limited", rate_limited_sampled))
  }
  
  // ç»Ÿè®¡é‡‡æ ·ç»“æœ
  let mut always_count = 0
  let mut never_count = 0
  let mut probabilistic_count = 0
  let mut rate_limited_count = 0
  
  for decision in sampling_decisions {
    match decision.0 {
      "always" => if decision.1 { always_count = always_count + 1 }
      "never" => if decision.1 { never_count = never_count + 1 }
      "probabilistic" => if decision.1 { probabilistic_count = probabilistic_count + 1 }
      "rate.limited" => if decision.1 { rate_limited_count = rate_limited_count + 1 }
      _ => ()
    }
  }
  
  // éªŒè¯é‡‡æ ·ç­–ç•¥
  assert_eq(always_count, 1000)  // Alwaysç­–ç•¥åº”è¯¥é‡‡æ ·æ‰€æœ‰1000ä¸ª
  assert_eq(never_count, 0)     // Neverç­–ç•¥åº”è¯¥é‡‡æ ·0ä¸ª
  assert_true(probabilistic_count >= 250 && probabilistic_count <= 350)  // æ¦‚ç‡ç­–ç•¥åº”è¯¥é‡‡æ ·çº¦30%
  assert_eq(rate_limited_count, 100)  // é€Ÿç‡é™åˆ¶ç­–ç•¥åº”è¯¥é‡‡æ ·100ä¸ª
  
  // æµ‹è¯•åŸºäºå±æ€§çš„é‡‡æ ·
  let high_priority_attrs = azimuth::Attributes::new()
  azimuth::Attributes::set(high_priority_attrs, "priority", azimuth::StringValue("high"))
  azimuth::Attributes::set(high_priority_attrs, "service.level", azimuth::StringValue("critical"))
  
  let low_priority_attrs = azimuth::Attributes::new()
  azimuth::Attributes::set(low_priority_attrs, "priority", azimuth::StringValue("low"))
  azimuth::Attributes::set(low_priority_attrs, "service.level", azimuth::StringValue("debug"))
  
  // é«˜ä¼˜å…ˆçº§åº¦é‡åº”è¯¥æ€»æ˜¯è¢«é‡‡æ ·
  for i = 0; i < 100; i = i + 1 {
    azimuth::Counter::add(always_counter, 1.0, Some(high_priority_attrs))
  }
  
  // ä½ä¼˜å…ˆçº§åº¦é‡å¯èƒ½è¢«é‡‡æ ·
  for i = 0; i < 100; i = i + 1 {
    if i % 5 == 0 {  // 20%é‡‡æ ·ç‡
      azimuth::Counter::add(never_counter, 1.0, Some(low_priority_attrs))
    }
  }
  
  // éªŒè¯åº¦é‡åˆ›å»º
  assert_eq(always_counter.name, "always.sampled")
  assert_eq(always_counter.description, Some("Always sampled counter"))
  assert_eq(always_counter.unit, Some("count"))
  
  assert_eq(never_counter.name, "never.sampled")
  assert_eq(never_counter.description, Some("Never sampled counter"))
  assert_eq(never_counter.unit, Some("count"))
  
  assert_eq(probabilistic_counter.name, "probabilistic.sampled")
  assert_eq(probabilistic_counter.description, Some("Probabilistic sampled counter"))
  assert_eq(probabilistic_counter.unit, Some("count"))
  
  assert_eq(rate_limited_counter.name, "rate.limited")
  assert_eq(rate_limited_counter.description, Some("Rate limited counter"))
  assert_eq(rate_limited_counter.unit, Some("count"))
}

// Test 6: ç½‘ç»œåˆ†åŒºå®¹é”™æµ‹è¯•
pub test "network partition fault tolerance test" {
  // æ¨¡æ‹Ÿç½‘ç»œåˆ†åŒºåœºæ™¯ä¸‹çš„é¥æµ‹æ•°æ®å¤„ç†
  let tracer_provider = azimuth::TracerProvider::default()
  let tracer = azimuth::TracerProvider::get_tracer(tracer_provider, "partition.test")
  
  let meter_provider = azimuth::MeterProvider::default()
  let meter = azimuth::MeterProvider::get_meter(meter_provider, "partition.test")
  
  let logger_provider = azimuth::LoggerProvider::default()
  let logger = azimuth::LoggerProvider::get_logger(logger_provider, "partition.test")
  
  // æ¨¡æ‹Ÿç½‘ç»œåˆ†åŒºå‰çš„æ­£å¸¸æ“ä½œ
  let normal_span = azimuth::Tracer::start_span(tracer, "normal.operation")
  azimuth::Span::add_event(normal_span, "operation.start", None)
  azimuth::Span::set_status(normal_span, azimuth::Ok)
  azimuth::Span::end(normal_span)
  
  let normal_counter = azimuth::Meter::create_counter(meter, "normal.operations")
  azimuth::Counter::add(normal_counter, 1.0)
  
  let normal_log = azimuth::LogRecord::new(azimuth::Info, "Normal operation completed")
  azimuth::Logger::emit(logger, normal_log)
  
  // æ¨¡æ‹Ÿç½‘ç»œåˆ†åŒºå¼€å§‹
  let partition_span = azimuth::Tracer::start_span(tracer, "partition.start")
  azimuth::Span::add_event(partition_span, "partition.detected", Some([
    ("partition.type", azimuth::StringValue("network.split")),
    ("affected.services", azimuth::StringValue("database,cache"))
  ]))
  
  // åœ¨ç½‘ç»œåˆ†åŒºæœŸé—´çš„æ“ä½œï¼ˆåº”è¯¥ç¼“å­˜æˆ–é™çº§å¤„ç†ï¼‰
  let partition_operations = []
  for i = 0; i < 50; i = i + 1 {
    let partition_op_span = azimuth::Tracer::start_span(tracer, "partition.operation")
    azimuth::Span::add_event(partition_op_span, "operation.cached", Some([
      ("operation.id", azimuth::IntValue(i)),
      ("cache.hit", azimuth::BoolValue(true))
    ]))
    azimuth::Span::set_status(partition_op_span, azimuth::Ok)
    azimuth::Span::end(partition_op_span)
    partition_operations.push(partition_op_span)
  }
  
  // åˆ†åŒºæœŸé—´çš„åº¦é‡ï¼ˆåº”è¯¥æœ¬åœ°ç¼“å­˜ï¼‰
  let partition_counter = azimuth::Meter::create_counter(meter, "partition.operations")
  for i = 0; i < 50; i = i + 1 {
    azimuth::Counter::add(partition_counter, 1.0)
  }
  
  // åˆ†åŒºæœŸé—´çš„æ—¥å¿—ï¼ˆåº”è¯¥æœ¬åœ°å­˜å‚¨ï¼‰
  for i = 0; i < 20; i = i + 1 {
    let partition_log = azimuth::LogRecord::new(azimuth::Warn, "Partition operation: " + i.to_string())
    azimuth::Logger::emit(logger, partition_log)
  }
  
  azimuth::Span::set_status(partition_span, azimuth::Ok)
  azimuth::Span::end(partition_span)
  
  // æ¨¡æ‹Ÿç½‘ç»œåˆ†åŒºæ¢å¤
  let recovery_span = azimuth::Tracer::start_span(tracer, "partition.recovery")
  azimuth::Span::add_event(recovery_span, "partition.recovered", Some([
    ("recovery.time", azimuth::IntValue(300)),  // 5åˆ†é’Ÿ
    ("cached.operations", azimuth::IntValue(50)),
    ("cached.metrics", azimuth::IntValue(50)),
    ("cached.logs", azimuth::IntValue(20))
  ]))
  
  // æ¨¡æ‹Ÿæ¢å¤åçš„æ•°æ®åŒæ­¥
  let sync_counter = azimuth::Meter::create_counter(meter, "synced.operations")
  for i = 0; i < 50; i = i + 1 {
    azimuth::Counter::add(sync_counter, 1.0)  // åŒæ­¥ç¼“å­˜çš„åº¦é‡
  }
  
  // æ¢å¤åçš„æ­£å¸¸æ“ä½œ
  let recovered_span = azimuth::Tracer::start_span(tracer, "recovered.operation")
  azimuth::Span::add_event(recovered_span, "operation.normal", None)
  azimuth::Span::set_status(recovered_span, azimuth::Ok)
  azimuth::Span::end(recovered_span)
  
  let recovered_log = azimuth::LogRecord::new(azimuth::Info, "Operation completed after partition recovery")
  azimuth::Logger::emit(logger, recovered_log)
  
  azimuth::Span::set_status(recovery_span, azimuth::Ok)
  azimuth::Span::end(recovery_span)
  
  // éªŒè¯æ‰€æœ‰spanå’Œåº¦é‡éƒ½æ­£ç¡®åˆ›å»º
  assert_eq(azimuth::Span::name(normal_span), "normal.operation")
  assert_eq(azimuth::Span::name(partition_span), "partition.start")
  assert_eq(azimuth::Span::name(recovery_span), "partition.recovery")
  assert_eq(azimuth::Span::name(recovered_span), "recovered.operation")
  
  assert_eq(normal_counter.name, "normal.operations")
  assert_eq(partition_counter.name, "partition.operations")
  assert_eq(sync_counter.name, "synced.operations")
  
  // éªŒè¯æ—¥å¿—è®°å½•
  assert_eq(azimuth::LogRecord::severity_number(normal_log), azimuth::Info)
  assert_eq(azimuth::LogRecord::body(normal_log), Some("Normal operation completed"))
  assert_eq(azimuth::LogRecord::severity_number(recovered_log), azimuth::Info)
  assert_eq(azimuth::LogRecord::body(recovered_log), Some("Operation completed after partition recovery"))
}

// Test 7: å†…å­˜æ³„æ¼é˜²æŠ¤æµ‹è¯•
pub test "memory leak protection test" {
  // æµ‹è¯•å¤§é‡å¯¹è±¡çš„åˆ›å»ºå’Œé”€æ¯ï¼Œç¡®ä¿æ²¡æœ‰å†…å­˜æ³„æ¼
  let object_lifecycle = []
  
  // ç¬¬ä¸€é˜¶æ®µï¼šåˆ›å»ºå¤§é‡å¯¹è±¡
  for i = 0; i < 100; i = i + 1 {
    // åˆ›å»ºèµ„æº
    let resource = azimuth::Resource::with_attributes(azimuth::Resource::new(), [
      ("lifecycle.phase", azimuth::StringValue("creation")),
      ("object.id", azimuth::IntValue(i)),
      ("memory.usage", azimuth::IntValue(i * 1024))
    ])
    
    // åˆ›å»ºä¸Šä¸‹æ–‡
    let ctx = azimuth::Context::root()
    let key = azimuth::ContextKey::new("lifecycle.key")
    let ctx_with_value = azimuth::Context::with_value(ctx, key, "lifecycle.value." + i.to_string())
    
    // åˆ›å»ºbaggage
    let baggage = azimuth::Baggage::new()
    let updated_baggage = azimuth::Baggage::set_entry(baggage, "lifecycle.entry", "lifecycle.value." + i.to_string())
    
    // åˆ›å»ºå±æ€§
    let attrs = azimuth::Attributes::new()
    azimuth::Attributes::set(attrs, "lifecycle.attr", azimuth::StringValue("lifecycle.value." + i.to_string()))
    
    // åˆ›å»ºspan
    let span_ctx = azimuth::SpanContext::new("lifecycle-trace-" + i.to_string(), "lifecycle-span-" + i.to_string(), true, "")
    let span = azimuth::Span::new("lifecycle.operation", azimuth::Internal, span_ctx)
    
    // åˆ›å»ºåº¦é‡
    let meter = azimuth::MeterProvider::get_meter(azimuth::MeterProvider::default(), "lifecycle.meter")
    let counter = azimuth::Meter::create_counter(meter, "lifecycle.counter")
    
    // åˆ›å»ºæ—¥å¿—è®°å½•
    let log = azimuth::LogRecord::new(azimuth::Info, "Lifecycle log " + i.to_string())
    
    object_lifecycle.push((resource, ctx_with_value, updated_baggage, attrs, span, counter, log))
  }
  
  // ç¬¬äºŒé˜¶æ®µï¼šä½¿ç”¨å¯¹è±¡
  for i = 0; i < object_lifecycle.length(); i = i + 1 {
    let (resource, ctx, baggage, attrs, span, counter, log) = object_lifecycle[i]
    
    // ä½¿ç”¨èµ„æº
    let object_id = azimuth::Resource::get_attribute(resource, "object.id")
    match object_id {
      Some(azimuth::IntValue(value)) => assert_eq(value, i)
      _ => assert_true(false)
    }
    
    // ä½¿ç”¨ä¸Šä¸‹æ–‡
    let key = azimuth::ContextKey::new("lifecycle.key")
    let ctx_value = azimuth::Context::get(ctx, key)
    assert_eq(ctx_value, Some("lifecycle.value." + i.to_string()))
    
    // ä½¿ç”¨baggage
    let baggage_value = azimuth::Baggage::get_entry(baggage, "lifecycle.entry")
    assert_eq(baggage_value, Some("lifecycle.value." + i.to_string()))
    
    // ä½¿ç”¨å±æ€§
    let attr_value = azimuth::Attributes::get(attrs, "lifecycle.attr")
    // åŸºäºç®€åŒ–å®ç°éªŒè¯
    assert_eq(attr_value, Some(azimuth::StringValue("test_value")))
    
    // ä½¿ç”¨span
    azimuth::Span::add_event(span, "lifecycle.event", Some([("phase", azimuth::StringValue("usage"))]))
    azimuth::Span::set_status(span, azimuth::Ok)
    
    // ä½¿ç”¨åº¦é‡
    azimuth::Counter::add(counter, 1.0)
    
    // ä½¿ç”¨æ—¥å¿—
    let logger = azimuth::LoggerProvider::get_logger(azimuth::LoggerProvider::default(), "lifecycle.logger")
    azimuth::Logger::emit(logger, log)
  }
  
  // ç¬¬ä¸‰é˜¶æ®µï¼šæ¸…ç†å¯¹è±¡ï¼ˆé€šè¿‡ç»“æŸspanå’Œç§»é™¤å¼•ç”¨ï¼‰
  for i = 0; i < object_lifecycle.length(); i = i + 1 {
    let (_, _, _, _, span, _, _) = object_lifecycle[i]
    azimuth::Span::end(span)
  }
  
  // ç¬¬å››é˜¶æ®µï¼šåˆ›å»ºæ–°å¯¹è±¡ä»¥æµ‹è¯•å†…å­˜é‡ç”¨
  let new_objects = []
  for i = 0; i < 50; i = i + 1 {
    let new_resource = azimuth::Resource::with_attributes(azimuth::Resource::new(), [
      ("lifecycle.phase", azimuth::StringValue("recreation")),
      ("object.id", azimuth::IntValue(i + 1000)),
      ("memory.reused", azimuth::BoolValue(true))
    ])
    new_objects.push(new_resource)
  }
  
  // éªŒè¯æ–°å¯¹è±¡æ­£ç¡®åˆ›å»º
  for i = 0; i < new_objects.length(); i = i + 1 {
    let resource = new_objects[i]
    let phase = azimuth::Resource::get_attribute(resource, "lifecycle.phase")
    match phase {
      Some(azimuth::StringValue(value)) => assert_eq(value, "recreation")
      _ => assert_true(false)
    }
    
    let object_id = azimuth::Resource::get_attribute(resource, "object.id")
    match object_id {
      Some(azimuth::IntValue(value)) => assert_eq(value, i + 1000)
      _ => assert_true(false)
    }
  }
  
  // éªŒè¯å†…å­˜ä½¿ç”¨ç¨³å®šï¼ˆé€šè¿‡å¯¹è±¡è®¡æ•°ï¼‰
  assert_true(object_lifecycle.length() == 100)
  assert_true(new_objects.length() == 50)
}

// Test 8: æ•°æ®å‹ç¼©å’Œæ‰¹é‡ä¼ è¾“æµ‹è¯•
pub test "data compression and batch transmission test" {
  // æ¨¡æ‹Ÿå¤§é‡é¥æµ‹æ•°æ®çš„å‹ç¼©å’Œæ‰¹é‡ä¼ è¾“
  let tracer_provider = azimuth::TracerProvider::default()
  let tracer = azimuth::TracerProvider::get_tracer(tracer_provider, "batch.test")
  
  let meter_provider = azimuth::MeterProvider::default()
  let meter = azimuth::MeterProvider::get_meter(meter_provider, "batch.test")
  
  let logger_provider = azimuth::LoggerProvider::default()
  let logger = azimuth::LoggerProvider::get_logger(logger_provider, "batch.test")
  
  // åˆ›å»ºå¤§é‡spanç”¨äºæ‰¹é‡å¤„ç†
  let batch_spans = []
  for i = 0; i < 100; i = i + 1 {
    let span = azimuth::Tracer::start_span(tracer, "batch.operation." + i.to_string())
    
    // æ·»åŠ å¤§é‡äº‹ä»¶ä»¥å¢åŠ æ•°æ®é‡
    for j = 0; j < 10; j = j + 1 {
      azimuth::Span::add_event(span, "batch.event." + j.to_string(), Some([
        ("event.id", azimuth::IntValue(i * 10 + j)),
        ("event.data", azimuth::StringValue("Large event data content for batch " + i.to_string() + " event " + j.to_string())),
        ("timestamp", azimuth::IntValue(1735689600 + i * 10 + j))
      ]))
    }
    
    // è®¾ç½®çŠ¶æ€
    if i % 10 == 0 {
      azimuth::Span::set_status(span, azimuth::Error, Some("Simulated error for testing"))
    } else {
      azimuth::Span::set_status(span, azimuth::Ok)
    }
    
    batch_spans.push(span)
  }
  
  // åˆ›å»ºå¤§é‡åº¦é‡ç”¨äºæ‰¹é‡å¤„ç†
  let batch_metrics = []
  let counters = []
  let histograms = []
  
  for i = 0; i < 20; i = i + 1 {
    let counter = azimuth::Meter::create_counter(meter, "batch.counter." + i.to_string())
    let histogram = azimuth::Meter::create_histogram(meter, "batch.histogram." + i.to_string())
    
    counters.push(counter)
    histograms.push(histogram)
    
    // è®°å½•å¤§é‡åº¦é‡æ•°æ®
    for j = 0; j < 50; j = j + 1 {
      let attrs = azimuth::Attributes::new()
      azimuth::Attributes::set(attrs, "batch.id", azimuth::IntValue(i))
      azimuth::Attributes::set(attrs, "measurement.id", azimuth::IntValue(j))
      azimuth::Attributes::set(attrs, "large.data", azimuth::StringValue("Large attribute data content for batch " + i.to_string() + " measurement " + j.to_string()))
      
      azimuth::Counter::add(counter, j.to_double(), Some(attrs))
      azimuth::Histogram::record(histogram, j.to_double() * 1.5, Some(attrs))
    }
  }
  
  // åˆ›å»ºå¤§é‡æ—¥å¿—ç”¨äºæ‰¹é‡å¤„ç†
  let batch_logs = []
  for i = 0; i < 200; i = i + 1 {
    let severity = if i % 5 == 0 { azimuth::Error } 
                   else if i % 3 == 0 { azimuth::Warn } 
                   else { azimuth::Info }
    
    let log_attrs = azimuth::Attributes::new()
    azimuth::Attributes::set(log_attrs, "log.id", azimuth::IntValue(i))
    azimuth::Attributes::set(log_attrs, "large.log.data", azimuth::StringValue("Large log data content for batch log entry " + i.to_string() + " with additional information to increase size"))
    
    let log = azimuth::LogRecord::new_with_context(
      severity,
      Some("Batch log message " + i.to_string() + " with additional content to increase data size"),
      Some(log_attrs),
      Some(1735689600000000000L + (i * 1000000L)),  // çº³ç§’ç²¾åº¦æ—¶é—´æˆ³
      Some(1735689600000000001L + (i * 1000000L)),
      Some("batch-trace-" + (i % 10).to_string()),
      Some("batch-span-" + i.to_string()),
      Some(azimuth::Context::root())
    )
    
    batch_logs.push(log)
  }
  
  // æ¨¡æ‹Ÿæ•°æ®å‹ç¼©ï¼ˆé€šè¿‡è®¡ç®—æ•°æ®å¤§å°ï¼‰
  let total_spans = batch_spans.length()
  let total_counters = counters.length()
  let total_histograms = histograms.length()
  let total_logs = batch_logs.length()
  
  // æ¨¡æ‹Ÿæ‰¹é‡ä¼ è¾“å‰çš„æ•°æ®å‡†å¤‡
  let batch_data = {
    "spans": total_spans,
    "counters": total_counters,
    "histograms": total_histograms,
    "logs": total_logs,
    "total.events": total_spans * 10,
    "total.measurements": counters.length() * 50,
    "compression.ratio": 0.3,  // å‡è®¾å‹ç¼©æ¯”ä¸º30%
    "batch.size": "large"
  }
  
  // éªŒè¯æ‰¹é‡æ•°æ®ç»Ÿè®¡
  assert_eq(total_spans, 100)
  assert_eq(total_counters, 20)
  assert_eq(total_histograms, 20)
  assert_eq(total_logs, 200)
  
  // æ¨¡æ‹Ÿæ‰¹é‡ä¼ è¾“
  let transmission_batches = []
  let batch_size = 50
  
  // æŒ‰æ‰¹æ¬¡å¤„ç†span
  for i = 0; i < batch_spans.length(); i = i + batch_size {
    let end_index = if i + batch_size > batch_spans.length() { batch_spans.length() } else { i + batch_size }
    let batch = []
    for j = i; j < end_index; j = j + 1 {
      batch.push(batch_spans[j])
    }
    transmission_batches.push(("spans", batch.length()))
    
    // ç»“æŸè¿™ä¸ªæ‰¹æ¬¡çš„span
    for span in batch {
      azimuth::Span::end(span)
    }
  }
  
  // æŒ‰æ‰¹æ¬¡å¤„ç†æ—¥å¿—
  for i = 0; i < batch_logs.length(); i = i + batch_size {
    let end_index = if i + batch_size > batch_logs.length() { batch_logs.length() } else { i + batch_size }
    let batch = []
    for j = i; j < end_index; j = j + 1 {
      batch.push(batch_logs[j])
    }
    transmission_batches.push(("logs", batch.length()))
    
    // å‘å‡ºè¿™ä¸ªæ‰¹æ¬¡çš„æ—¥å¿—
    for log in batch {
      azimuth::Logger::emit(logger, log)
    }
  }
  
  // éªŒè¯æ‰¹æ¬¡å¤„ç†
  let mut total_span_batches = 0
  let mut total_log_batches = 0
  
  for batch in transmission_batches {
    match batch.0 {
      "spans" => total_span_batches = total_span_batches + batch.1
      "logs" => total_log_batches = total_log_batches + batch.1
      _ => ()
    }
  }
  
  assert_eq(total_span_batches, 100)  // æ‰€æœ‰spanéƒ½åº”è¯¥è¢«å¤„ç†
  assert_eq(total_log_batches, 200)   // æ‰€æœ‰æ—¥å¿—éƒ½åº”è¯¥è¢«å¤„ç†
  
  // éªŒè¯å‹ç¼©æ•ˆæœï¼ˆé€šè¿‡æ¨¡æ‹Ÿï¼‰
  let original_size = (total_spans * 1000) + (total_logs * 500) + (total_counters * 200)  // æ¨¡æ‹ŸåŸå§‹å¤§å°
  let compressed_size = (original_size.to_double() * 0.3).to_int()  // å‹ç¼©åå¤§å°
  
  assert_true(compressed_size < original_size)  // å‹ç¼©ååº”è¯¥æ›´å°
  assert_true(compressed_size > 0)  // å‹ç¼©åå¤§å°åº”è¯¥å¤§äº0
}