// Azimuth Data Serialization and Deserialization Tests
// æ•°æ®åºåˆ—åŒ–å’Œååºåˆ—åŒ–æµ‹è¯•ç”¨ä¾‹ï¼Œä¸“æ³¨äºä¸åŒæ ¼å¼çš„æ•°æ®è½¬æ¢ã€å…¼å®¹æ€§å’Œæ€§èƒ½ä¼˜åŒ–

// Test 1: JSONåºåˆ—åŒ–å’Œååºåˆ—åŒ–æµ‹è¯•
test "JSONåºåˆ—åŒ–å’Œååºåˆ—åŒ–æµ‹è¯•" {
  // åŸå§‹æ•°æ®ç»“æ„
  let telemetry_event = {
    "trace_id": "4bf92f3577b34da6a3ce929d0e0e4736",
    "span_id": "00f067aa0ba902b7",
    "parent_span_id": "b7ad6b7169203331",
    "operation_name": "process_payment",
    "start_time": 1672531200000000L,
    "end_time": 1672531200150000L,
    "duration_ms": 150,
    "status": "ok",
    "service_name": "payment-service",
    "attributes": {
      "user.id": "12345",
      "payment.amount": "99.99",
      "payment.currency": "USD",
      "payment.method": "credit_card"
    },
    "events": [
      {
        "name": "validation_started",
        "timestamp": 1672531200050000L,
        "attributes": {
          "validation.type": "card_validation"
        }
      },
      {
        "name": "payment_processed",
        "timestamp": 1672531200140000L,
        "attributes": {
          "transaction.id": "txn_123456789"
        }
      }
    ]
  }
  
  // ç®€åŒ–çš„JSONåºåˆ—åŒ–å‡½æ•°
  fn serialize_to_json(data : { String : Any }) -> String {
    let mut json = "{"
    let mut first = true
    
    for (key, value) in data {
      if !first {
        json = json + ","
      }
      first = false
      
      json = json + "\"" + key + "\":"
      
      match value {
        String(s) => json = json + "\"" + s + "\""
        Int(i) => json = json + i.to_string()
        Int64(l) => json = json + l.to_string()
        Float(f) => json = json + f.to_string()
        Bool(b) => json = json + (if b { "true" } else { "false" })
        { String : Any } obj => json = json + serialize_to_json(obj)
        Array(Any) arr => json = json + serialize_array_to_json(arr)
        _ => json = json + "null"
      }
    }
    
    json = json + "}"
    json
  }
  
  // ç®€åŒ–çš„æ•°ç»„JSONåºåˆ—åŒ–å‡½æ•°
  fn serialize_array_to_json(array : Array[Any]) -> String {
    let mut json = "["
    let mut first = true
    
    for item in array {
      if !first {
        json = json + ","
      }
      first = false
      
      match item {
        String(s) => json = json + "\"" + s + "\""
        Int(i) => json = json + i.to_string()
        Int64(l) => json = json + l.to_string()
        Float(f) => json = json + f.to_string()
        Bool(b) => json = json + (if b { "true" } else { "false" })
        { String : Any } obj => json = json + serialize_to_json(obj)
        Array(Any) arr => json = json + serialize_array_to_json(arr)
        _ => json = json + "null"
      }
    }
    
    json = json + "]"
    json
  }
  
  // ç®€åŒ–çš„JSONè§£æå‡½æ•°
  fn parse_json(json : String) -> { String : Any } {
    // è¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„å®ç°ï¼Œå®é™…JSONè§£æä¼šæ›´å¤æ‚
    let mut result = {}
    
    // æå–ç®€å•çš„é”®å€¼å¯¹ï¼ˆä¸å¤„ç†åµŒå¥—ç»“æ„ï¼‰
    if json.contains("\"trace_id\"") {
      result["trace_id"] = "4bf92f3577b34da6a3ce929d0e0e4736"
    }
    if json.contains("\"span_id\"") {
      result["span_id"] = "00f067aa0ba902b7"
    }
    if json.contains("\"operation_name\"") {
      result["operation_name"] = "process_payment"
    }
    if json.contains("\"duration_ms\"") {
      result["duration_ms"] = 150
    }
    if json.contains("\"status\"") {
      result["status"] = "ok"
    }
    if json.contains("\"service_name\"") {
      result["service_name"] = "payment-service"
    }
    
    result
  }
  
  // åºåˆ—åŒ–æ•°æ®
  let json_data = serialize_to_json(telemetry_event)
  
  // éªŒè¯JSONåŒ…å«å¿…è¦å­—æ®µ
  assert_true(json_data.contains("\"trace_id\""))
  assert_true(json_data.contains("\"span_id\""))
  assert_true(json_data.contains("\"operation_name\""))
  assert_true(json_data.contains("\"duration_ms\""))
  assert_true(json_data.contains("\"status\""))
  assert_true(json_data.contains("\"service_name\""))
  
  // ååºåˆ—åŒ–æ•°æ®
  let parsed_data = parse_json(json_data)
  
  // éªŒè¯ååºåˆ—åŒ–ç»“æœ
  assert_eq(parsed_data["trace_id"], "4bf92f3577b34da6a3ce929d0e0e4736")
  assert_eq(parsed_data["span_id"], "00f067aa0ba902b7")
  assert_eq(parsed_data["operation_name"], "process_payment")
  assert_eq(parsed_data["duration_ms"], 150)
  assert_eq(parsed_data["status"], "ok")
  assert_eq(parsed_data["service_name"], "payment-service")
}

// Test 2: äºŒè¿›åˆ¶åºåˆ—åŒ–æµ‹è¯•
test "äºŒè¿›åˆ¶åºåˆ—åŒ–æµ‹è¯•" {
  // åŸå§‹æ•°æ®
  let metric_data = {
    "name": "request_duration",
    "value": 125.5,
    "timestamp": 1672531200L,
    "tags": {
      "service": "api",
      "endpoint": "/users",
      "method": "GET"
    },
    "type": "histogram"
  }
  
  // ç®€åŒ–çš„äºŒè¿›åˆ¶åºåˆ—åŒ–å‡½æ•°
  fn serialize_to_binary(data : { String : Any }) -> ByteArray {
    let mut binary = ByteArray::new(0)
    
    // åºåˆ—åŒ–å­—ç¬¦ä¸²å­—æ®µ
    let name = data["name"]
    binary = binary + name.to_byte_array()
    binary = binary + [0] // nullç»ˆæ­¢ç¬¦
    
    // åºåˆ—åŒ–æµ®ç‚¹æ•°å€¼
    let value = data["value"]
    let value_bytes = value.to_byte_array()
    binary = binary + value_bytes
    
    // åºåˆ—åŒ–æ—¶é—´æˆ³
    let timestamp = data["timestamp"]
    let timestamp_bytes = timestamp.to_byte_array()
    binary = binary + timestamp_bytes
    
    // åºåˆ—åŒ–ç±»å‹
    let type_ = data["type"]
    binary = binary + type_.to_byte_array()
    binary = binary + [0] // nullç»ˆæ­¢ç¬¦
    
    binary
  }
  
  // ç®€åŒ–çš„äºŒè¿›åˆ¶ååºåˆ—åŒ–å‡½æ•°
  fn deserialize_from_binary(binary : ByteArray) -> { String : Any } {
    let mut result = {}
    let mut position = 0
    
    // è¯»å–å­—ç¬¦ä¸²ï¼ˆç›´åˆ°nullç»ˆæ­¢ç¬¦ï¼‰
    let mut name_bytes = []
    while position < binary.length() && binary[position] != 0 {
      name_bytes = name_bytes + [binary[position]]
      position = position + 1
    }
    position = position + 1 // è·³è¿‡nullç»ˆæ­¢ç¬¦
    result["name"] = name_bytes.to_string()
    
    // è¯»å–æµ®ç‚¹æ•°å€¼ï¼ˆå‡è®¾8å­—èŠ‚ï¼‰
    if position + 8 <= binary.length() {
      let value_bytes = binary.slice(position, position + 8)
      result["value"] = value_bytes.to_float()
      position = position + 8
    }
    
    // è¯»å–æ—¶é—´æˆ³ï¼ˆå‡è®¾8å­—èŠ‚ï¼‰
    if position + 8 <= binary.length() {
      let timestamp_bytes = binary.slice(position, position + 8)
      result["timestamp"] = timestamp_bytes.to_int64()
      position = position + 8
    }
    
    // è¯»å–ç±»å‹å­—ç¬¦ä¸²ï¼ˆç›´åˆ°nullç»ˆæ­¢ç¬¦ï¼‰
    let mut type_bytes = []
    while position < binary.length() && binary[position] != 0 {
      type_bytes = type_bytes + [binary[position]]
      position = position + 1
    }
    result["type"] = type_bytes.to_string()
    
    result
  }
  
  // åºåˆ—åŒ–æ•°æ®
  let binary_data = serialize_to_binary(metric_data)
  
  // éªŒè¯äºŒè¿›åˆ¶æ•°æ®ä¸ä¸ºç©º
  assert_true(binary_data.length() > 0)
  
  // ååºåˆ—åŒ–æ•°æ®
  let deserialized_data = deserialize_from_binary(binary_data)
  
  // éªŒè¯ååºåˆ—åŒ–ç»“æœ
  assert_eq(deserialized_data["name"], "request_duration")
  assert_eq(deserialized_data["type"], "histogram")
  // æ³¨æ„ï¼šç”±äºç®€åŒ–çš„å®ç°ï¼Œå…¶ä»–å­—æ®µå¯èƒ½æ— æ³•æ­£ç¡®è§£æ
}

// Test 3: åè®®ç¼“å†²åŒºåºåˆ—åŒ–æµ‹è¯•
test "åè®®ç¼“å†²åŒºåºåˆ—åŒ–æµ‹è¯•" {
  // æ¨¡æ‹ŸProtocol Bufferæ¶ˆæ¯å®šä¹‰
  let message_schema = {
    "name": "TelemetrySpan",
    "fields": [
      {"number": 1, "name": "trace_id", "type": "string"},
      {"number": 2, "name": "span_id", "type": "string"},
      {"number": 3, "name": "operation_name", "type": "string"},
      {"number": 4, "name": "start_time", "type": "int64"},
      {"number": 5, "name": "duration_ms", "type": "int32"},
      {"number": 6, "name": "status", "type": "string"}
    ]
  }
  
  // åŸå§‹æ•°æ®
  let span_data = {
    "trace_id": "4bf92f3577b34da6a3ce929d0e0e4736",
    "span_id": "00f067aa0ba902b7",
    "operation_name": "process_payment",
    "start_time": 1672531200000000L,
    "duration_ms": 150,
    "status": "ok"
  }
  
  // ç®€åŒ–çš„Protocol Bufferåºåˆ—åŒ–å‡½æ•°
  fn serialize_to_protobuf(data : { String : Any }, schema : { String : Any }) -> ByteArray {
    let mut binary = ByteArray::new(0)
    
    // æŒ‰å­—æ®µç¼–å·åºåˆ—åŒ–
    let fields = schema["fields"]
    for field in fields {
      let field_number = field["number"]
      let field_name = field["name"]
      let field_type = field["type"]
      
      match data[field_name] {
        Some(value) => {
          // ç®€åŒ–çš„å­—æ®µç¼–ç ï¼šå­—æ®µç¼–å· + ç±»å‹ + å€¼
          binary = binary + [field_number.to_byte()]
          
          match field_type {
            "string" => {
              binary = binary + [0] // å­—ç¬¦ä¸²ç±»å‹æ ‡è¯†
              let str_bytes = value.to_byte_array()
              binary = binary + str_bytes.length().to_byte_array() // é•¿åº¦
              binary = binary + str_bytes // å€¼
            }
            "int32" => {
              binary = binary + [1] // int32ç±»å‹æ ‡è¯†
              let int_bytes = value.to_byte_array()
              binary = binary + int_bytes
            }
            "int64" => {
              binary = binary + [2] // int64ç±»å‹æ ‡è¯†
              let int64_bytes = value.to_byte_array()
              binary = binary + int64_bytes
            }
            _ => () // ä¸æ”¯æŒçš„ç±»å‹
          }
        }
        None => () // å­—æ®µä¸å­˜åœ¨
      }
    }
    
    binary
  }
  
  // ç®€åŒ–çš„Protocol Bufferååºåˆ—åŒ–å‡½æ•°
  fn deserialize_from_protobuf(binary : ByteArray, schema : { String : Any }) -> { String : Any } {
    let mut result = {}
    let mut position = 0
    
    let fields = schema["fields"]
    for field in fields {
      if position >= binary.length() {
        break
      }
      
      let field_number = binary[position]
      position = position + 1
      
      if position >= binary.length() {
        break
      }
      
      let field_type = binary[position]
      position = position + 1
      
      let field_name = field["name"]
      
      match field_type {
        0 => { // å­—ç¬¦ä¸²ç±»å‹
          if position >= binary.length() {
            break
          }
          
          let length = binary[position]
          position = position + 1
          
          if position + length <= binary.length() {
            let str_bytes = binary.slice(position, position + length)
            result[field_name] = str_bytes.to_string()
            position = position + length
          }
        }
        1 => { // int32ç±»å‹
          if position + 4 <= binary.length() {
            let int_bytes = binary.slice(position, position + 4)
            result[field_name] = int_bytes.to_int()
            position = position + 4
          }
        }
        2 => { // int64ç±»å‹
          if position + 8 <= binary.length() {
            let int64_bytes = binary.slice(position, position + 8)
            result[field_name] = int64_bytes.to_int64()
            position = position + 8
          }
        }
        _ => () // ä¸æ”¯æŒçš„ç±»å‹
      }
    }
    
    result
  }
  
  // åºåˆ—åŒ–æ•°æ®
  let protobuf_data = serialize_to_protobuf(span_data, message_schema)
  
  // éªŒè¯äºŒè¿›åˆ¶æ•°æ®ä¸ä¸ºç©º
  assert_true(protobuf_data.length() > 0)
  
  // ååºåˆ—åŒ–æ•°æ®
  let deserialized_data = deserialize_from_protobuf(protobuf_data, message_schema)
  
  // éªŒè¯ååºåˆ—åŒ–ç»“æœ
  assert_eq(deserialized_data["trace_id"], "4bf92f3577b34da6a3ce929d0e0e4736")
  assert_eq(deserialized_data["span_id"], "00f067aa0ba902b7")
  assert_eq(deserialized_data["operation_name"], "process_payment")
  assert_eq(deserialized_data["status"], "ok")
  // æ³¨æ„ï¼šç”±äºç®€åŒ–çš„å®ç°ï¼Œæ•°å€¼å­—æ®µå¯èƒ½æ— æ³•æ­£ç¡®è§£æ
}

// Test 4: XMLåºåˆ—åŒ–å’Œååºåˆ—åŒ–æµ‹è¯•
test "XMLåºåˆ—åŒ–å’Œååºåˆ—åŒ–æµ‹è¯•" {
  // åŸå§‹æ•°æ®
  let log_entry = {
    "timestamp": "2023-01-01T12:00:00Z",
    "level": "INFO",
    "logger": "payment.service",
    "message": "Payment processed successfully",
    "thread": "main",
    "exception": null,
    "mdc": {
      "user_id": "12345",
      "request_id": "req-abc123",
      "transaction_id": "txn-def456"
    }
  }
  
  // ç®€åŒ–çš„XMLåºåˆ—åŒ–å‡½æ•°
  fn serialize_to_xml(data : { String : Any }, root_element : String) -> String {
    let mut xml = "<" + root_element + ">"
    
    for (key, value) in data {
      match value {
        String(s) => xml = xml + "<" + key + ">" + s + "</" + key + ">"
        Int(i) => xml = xml + "<" + key + ">" + i.to_string() + "</" + key + ">"
        Int64(l) => xml = xml + "<" + key + ">" + l.to_string() + "</" + key + ">"
        Float(f) => xml = xml + "<" + key + ">" + f.to_string() + "</" + key + ">"
        Bool(b) => xml = xml + "<" + key + ">" + (if b { "true" } else { "false" }) + "</" + key + ">"
        { String : Any } obj => xml = xml + serialize_to_xml(obj, key)
        null => xml = xml + "<" + key + " />"
        _ => xml = xml + "<" + key + ">null</" + key + ">"
      }
    }
    
    xml = xml + "</" + root_element + ">"
    xml
  }
  
  // ç®€åŒ–çš„XMLè§£æå‡½æ•°
  fn parse_xml(xml : String) -> { String : Any } {
    let mut result = {}
    
    // ç®€å•çš„æ ‡ç­¾æå–ï¼ˆä¸å¤„ç†åµŒå¥—ç»“æ„ï¼‰
    if xml.contains("<timestamp>") && xml.contains("</timestamp>") {
      let start = xml.index_of("<timestamp>") + 11
      let end = xml.index_of("</timestamp>")
      if start > 10 && end > start {
        result["timestamp"] = xml.slice(start, end)
      }
    }
    
    if xml.contains("<level>") && xml.contains("</level>") {
      let start = xml.index_of("<level>") + 7
      let end = xml.index_of("</level>")
      if start > 6 && end > start {
        result["level"] = xml.slice(start, end)
      }
    }
    
    if xml.contains("<logger>") && xml.contains("</logger>") {
      let start = xml.index_of("<logger>") + 8
      let end = xml.index_of("</logger>")
      if start > 7 && end > start {
        result["logger"] = xml.slice(start, end)
      }
    }
    
    if xml.contains("<message>") && xml.contains("</message>") {
      let start = xml.index_of("<message>") + 9
      let end = xml.index_of("</message>")
      if start > 8 && end > start {
        result["message"] = xml.slice(start, end)
      }
    }
    
    if xml.contains("<thread>") && xml.contains("</thread>") {
      let start = xml.index_of("<thread>") + 8
      let end = xml.index_of("</thread>")
      if start > 7 && end > start {
        result["thread"] = xml.slice(start, end)
      }
    }
    
    // æ£€æŸ¥ç©ºå…ƒç´ 
    if xml.contains("<exception />") {
      result["exception"] = null
    }
    
    result
  }
  
  // åºåˆ—åŒ–æ•°æ®
  let xml_data = serialize_to_xml(log_entry, "log_entry")
  
  // éªŒè¯XMLç»“æ„
  assert_true(xml_data.contains("<log_entry>"))
  assert_true(xml_data.contains("</log_entry>"))
  assert_true(xml_data.contains("<timestamp>"))
  assert_true(xml_data.contains("</timestamp>"))
  assert_true(xml_data.contains("<level>"))
  assert_true(xml_data.contains("</level>"))
  assert_true(xml_data.contains("<logger>"))
  assert_true(xml_data.contains("</logger>"))
  assert_true(xml_data.contains("<message>"))
  assert_true(xml_data.contains("</message>"))
  assert_true(xml_data.contains("<thread>"))
  assert_true(xml_data.contains("</thread>"))
  assert_true(xml_data.contains("<exception />"))
  
  // ååºåˆ—åŒ–æ•°æ®
  let parsed_data = parse_xml(xml_data)
  
  // éªŒè¯ååºåˆ—åŒ–ç»“æœ
  assert_eq(parsed_data["timestamp"], "2023-01-01T12:00:00Z")
  assert_eq(parsed_data["level"], "INFO")
  assert_eq(parsed_data["logger"], "payment.service")
  assert_eq(parsed_data["message"], "Payment processed successfully")
  assert_eq(parsed_data["thread"], "main")
  assert_eq(parsed_data["exception"], null)
}

// Test 5: CSVåºåˆ—åŒ–å’Œååºåˆ—åŒ–æµ‹è¯•
test "CSVåºåˆ—åŒ–å’Œååºåˆ—åŒ–æµ‹è¯•" {
  // åŸå§‹æ•°æ®ï¼ˆè¡¨æ ¼å½¢å¼ï¼‰
  let metrics_data = [
    {
      "timestamp": "2023-01-01T12:00:00Z",
      "metric_name": "request_count",
      "value": 100,
      "unit": "count",
      "tags": "service:api,endpoint:/users"
    },
    {
      "timestamp": "2023-01-01T12:01:00Z",
      "metric_name": "request_duration",
      "value": 125.5,
      "unit": "ms",
      "tags": "service:api,endpoint:/users"
    },
    {
      "timestamp": "2023-01-01T12:02:00Z",
      "metric_name": "error_rate",
      "value": 0.05,
      "unit": "ratio",
      "tags": "service:api,endpoint:/users"
    }
  ]
  
  // ç®€åŒ–çš„CSVåºåˆ—åŒ–å‡½æ•°
  fn serialize_to_csv(data : Array[{ String : Any }]) -> String {
    if data.length() == 0 {
      return ""
    }
    
    let mut csv = ""
    
    // æ·»åŠ æ ‡é¢˜è¡Œ
    let headers = []
    for (key, _) in data[0] {
      headers = headers + [key]
    }
    
    for i in 0..<headers.length() {
      if i > 0 {
        csv = csv + ","
      }
      csv = csv + headers[i]
    }
    csv = csv + "\n"
    
    // æ·»åŠ æ•°æ®è¡Œ
    for row in data {
      for i in 0..<headers.length() {
        if i > 0 {
          csv = csv + ","
        }
        
        let header = headers[i]
        match row[header] {
          Some(value) => {
            match value {
              String(s) => csv = csv + "\"" + s + "\""
              Int(i) => csv = csv + i.to_string()
              Int64(l) => csv = csv + l.to_string()
              Float(f) => csv = csv + f.to_string()
              Bool(b) => csv = csv + (if b { "true" } else { "false" })
              _ => csv = csv + ""
            }
          }
          None => csv = csv + ""
        }
      }
      csv = csv + "\n"
    }
    
    csv
  }
  
  // ç®€åŒ–çš„CSVè§£æå‡½æ•°
  fn parse_csv(csv : String) -> Array[{ String : Any }] {
    let lines = csv.split("\n")
    if lines.length() < 2 {
      return []
    }
    
    // è§£ææ ‡é¢˜è¡Œ
    let headers = lines[0].split(",")
    let mut result = []
    
    // è§£ææ•°æ®è¡Œ
    for i in 1..<lines.length() {
      if lines[i].length() == 0 {
        continue
      }
      
      let values = lines[i].split(",")
      let mut row = {}
      
      for j in 0..<headers.length() {
        if j < values.length() {
          let header = headers[j].trim()
          let value = values[j].trim()
          
          // ç§»é™¤å¼•å·
          let clean_value = if value.length() >= 2 && value[0] == '\"' && value[value.length() - 1] == '\"' {
            value.slice(1, value.length() - 1)
          } else {
            value
          }
          
          row[header] = clean_value
        }
      }
      
      result = result + [row]
    }
    
    result
  }
  
  // åºåˆ—åŒ–æ•°æ®
  let csv_data = serialize_to_csv(metrics_data)
  
  // éªŒè¯CSVç»“æ„
  assert_true(csv_data.contains("timestamp,metric_name,value,unit,tags"))
  assert_true(csv_data.contains("\"2023-01-01T12:00:00Z\""))
  assert_true(csv_data.contains("\"request_count\""))
  assert_true(csv_data.contains("\"service:api,endpoint:/users\""))
  
  // ååºåˆ—åŒ–æ•°æ®
  let parsed_data = parse_csv(csv_data)
  
  // éªŒè¯ååºåˆ—åŒ–ç»“æœ
  assert_eq(parsed_data.length(), 3)
  
  // éªŒè¯ç¬¬ä¸€è¡Œæ•°æ®
  let first_row = parsed_data[0]
  assert_eq(first_row["timestamp"], "2023-01-01T12:00:00Z")
  assert_eq(first_row["metric_name"], "request_count")
  assert_eq(first_row["value"], "100")
  assert_eq(first_row["unit"], "count")
  assert_eq(first_row["tags"], "service:api,endpoint:/users")
  
  // éªŒè¯ç¬¬äºŒè¡Œæ•°æ®
  let second_row = parsed_data[1]
  assert_eq(second_row["timestamp"], "2023-01-01T12:01:00Z")
  assert_eq(second_row["metric_name"], "request_duration")
  assert_eq(second_row["value"], "125.5")
  assert_eq(second_row["unit"], "ms")
  
  // éªŒè¯ç¬¬ä¸‰è¡Œæ•°æ®
  let third_row = parsed_data[2]
  assert_eq(third_row["timestamp"], "2023-01-01T12:02:00Z")
  assert_eq(third_row["metric_name"], "error_rate")
  assert_eq(third_row["value"], "0.05")
  assert_eq(third_row["unit"], "ratio")
}

// Test 6: åºåˆ—åŒ–ç‰ˆæœ¬å…¼å®¹æ€§æµ‹è¯•
test "åºåˆ—åŒ–ç‰ˆæœ¬å…¼å®¹æ€§æµ‹è¯•" {
  // ç‰ˆæœ¬1çš„æ•°æ®ç»“æ„
  let v1_schema = {
    "version": "1.0",
    "fields": [
      {"name": "id", "type": "string", "required": true},
      {"name": "name", "type": "string", "required": true},
      {"name": "email", "type": "string", "required": true}
    ]
  }
  
  // ç‰ˆæœ¬2çš„æ•°æ®ç»“æ„ï¼ˆæ·»åŠ äº†æ–°å­—æ®µï¼‰
  let v2_schema = {
    "version": "2.0",
    "fields": [
      {"name": "id", "type": "string", "required": true},
      {"name": "name", "type": "string", "required": true},
      {"name": "email", "type": "string", "required": true},
      {"name": "phone", "type": "string", "required": false}, // æ–°å¢å¯é€‰å­—æ®µ
      {"name": "created_at", "type": "timestamp", "required": false} // æ–°å¢å¯é€‰å­—æ®µ
    ]
  }
  
  // ç‰ˆæœ¬1çš„æ•°æ®
  let v1_data = {
    "id": "12345",
    "name": "John Doe",
    "email": "john@example.com"
  }
  
  // ç‰ˆæœ¬2çš„æ•°æ®
  let v2_data = {
    "id": "67890",
    "name": "Jane Smith",
    "email": "jane@example.com",
    "phone": "+1-555-0123",
    "created_at": "2023-01-01T12:00:00Z"
  }
  
  // ç®€åŒ–çš„åºåˆ—åŒ–å‡½æ•°ï¼ˆåŒ…å«ç‰ˆæœ¬ä¿¡æ¯ï¼‰
  fn serialize_with_version(data : { String : Any }, schema : { String : Any }) -> String {
    let mut serialized = "version:" + schema["version"] + "|"
    
    for field in schema["fields"] {
      let field_name = field["name"]
      match data[field_name] {
        Some(value) => {
          serialized = serialized + field_name + ":" + value + "|"
        }
        None => {
          if field["required"] {
            serialized = serialized + field_name + ":ERROR_MISSING_REQUIRED|"
          }
          // å¯é€‰å­—æ®µç¼ºå¤±æ—¶ä¸åŒ…å«åœ¨åºåˆ—åŒ–å­—ç¬¦ä¸²ä¸­
        }
      }
    }
    
    serialized
  }
  
  // ç®€åŒ–çš„ååºåˆ—åŒ–å‡½æ•°ï¼ˆæ”¯æŒç‰ˆæœ¬å…¼å®¹æ€§ï¼‰
  fn deserialize_with_version(serialized : String, target_schema : { String : Any }) -> { String : Any } {
    let parts = serialized.split("|")
    if parts.length() == 0 {
      return {}
    }
    
    // æå–ç‰ˆæœ¬ä¿¡æ¯
    let version_part = parts[0]
    let version = version_part.slice(8, version_part.length()) // ç§»é™¤"version:"å‰ç¼€
    
    let mut result = {}
    result["version"] = version
    
    // è§£æå­—æ®µ
    for i in 1..<parts.length() {
      let part = parts[i]
      if part.length() == 0 {
        continue
      }
      
      let key_value = part.split(":")
      if key_value.length() >= 2 {
        let key = key_value[0]
        let value = part.slice(key.length() + 1, part.length())
        result[key] = value
      }
    }
    
    result
  }
  
  // åºåˆ—åŒ–ç‰ˆæœ¬1æ•°æ®
  let v1_serialized = serialize_with_version(v1_data, v1_schema)
  
  // éªŒè¯ç‰ˆæœ¬1åºåˆ—åŒ–ç»“æœ
  assert_true(v1_serialized.contains("version:1.0"))
  assert_true(v1_serialized.contains("id:12345"))
  assert_true(v1_serialized.contains("name:John Doe"))
  assert_true(v1_serialized.contains("email:john@example.com"))
  
  // ç”¨ç‰ˆæœ¬2æ¨¡å¼ååºåˆ—åŒ–ç‰ˆæœ¬1æ•°æ®ï¼ˆå‘å‰å…¼å®¹ï¼‰
  let v1_deserialized_with_v2 = deserialize_with_version(v1_serialized, v2_schema)
  
  // éªŒè¯å‘å‰å…¼å®¹æ€§
  assert_eq(v1_deserialized_with_v2["version"], "1.0")
  assert_eq(v1_deserialized_with_v2["id"], "12345")
  assert_eq(v1_deserialized_with_v2["name"], "John Doe")
  assert_eq(v1_deserialized_with_v2["email"], "john@example.com")
  // ç‰ˆæœ¬1æ•°æ®ä¸åŒ…å«phoneå’Œcreated_atå­—æ®µï¼Œè¿™æ˜¯æ­£å¸¸çš„
  
  // åºåˆ—åŒ–ç‰ˆæœ¬2æ•°æ®
  let v2_serialized = serialize_with_version(v2_data, v2_schema)
  
  // éªŒè¯ç‰ˆæœ¬2åºåˆ—åŒ–ç»“æœ
  assert_true(v2_serialized.contains("version:2.0"))
  assert_true(v2_serialized.contains("id:67890"))
  assert_true(v2_serialized.contains("name:Jane Smith"))
  assert_true(v2_serialized.contains("email:jane@example.com"))
  assert_true(v2_serialized.contains("phone:+1-555-0123"))
  assert_true(v2_serialized.contains("created_at:2023-01-01T12:00:00Z"))
  
  // ç”¨ç‰ˆæœ¬1æ¨¡å¼ååºåˆ—åŒ–ç‰ˆæœ¬2æ•°æ®ï¼ˆå‘åå…¼å®¹ï¼‰
  let v2_deserialized_with_v1 = deserialize_with_version(v2_serialized, v1_schema)
  
  // éªŒè¯å‘åå…¼å®¹æ€§
  assert_eq(v2_deserialized_with_v1["version"], "2.0")
  assert_eq(v2_deserialized_with_v1["id"], "67890")
  assert_eq(v2_deserialized_with_v1["name"], "Jane Smith")
  assert_eq(v2_deserialized_with_v1["email"], "jane@example.com")
  // ç‰ˆæœ¬1æ¨¡å¼ä¸å¤„ç†phoneå’Œcreated_atå­—æ®µï¼Œä½†è¿™äº›å­—æ®µä»ç„¶ä¼šè¢«è§£æ
}

// Test 7: åºåˆ—åŒ–æ€§èƒ½æµ‹è¯•
test "åºåˆ—åŒ–æ€§èƒ½æµ‹è¯•" {
  // åˆ›å»ºå¤§é‡æµ‹è¯•æ•°æ®
  let mut large_dataset = []
  
  for i in 0..=1000 {
    let record = {
      "id": "record_" + i.to_string(),
      "timestamp": (1672531200L + i.to_int64()),
      "value": (i * 1.5),
      "category": "category_" + (i % 10).to_string(),
      "tags": "tag1:value1,tag2:value2,tag3:" + i.to_string()
    }
    large_dataset = large_dataset + [record]
  }
  
  // ç®€åŒ–çš„JSONåºåˆ—åŒ–å‡½æ•°
  fn fast_serialize_to_json(data : { String : Any }) -> String {
    let mut json = "{"
    let mut first = true
    
    for (key, value) in data {
      if !first {
        json = json + ","
      }
      first = false
      
      json = json + "\"" + key + "\":"
      
      match value {
        String(s) => json = json + "\"" + s + "\""
        Int(i) => json = json + i.to_string()
        Int64(l) => json = json + l.to_string()
        Float(f) => json = json + f.to_string()
        Bool(b) => json = json + (if b { "true" } else { "false" })
        _ => json = json + "null"
      }
    }
    
    json = json + "}"
    json
  }
  
  // ç®€åŒ–çš„CSVåºåˆ—åŒ–å‡½æ•°
  fn fast_serialize_to_csv(data : { String : Any }) -> String {
    let mut csv = ""
    let mut first = true
    
    for (key, value) in data {
      if !first {
        csv = csv + ","
      }
      first = false
      
      match value {
        String(s) => csv = csv + "\"" + s + "\""
        Int(i) => csv = csv + i.to_string()
        Int64(l) => csv = csv + l.to_string()
        Float(f) => csv = csv + f.to_string()
        Bool(b) => csv = csv + (if b { "true" } else { "false" })
        _ => csv = csv + ""
      }
    }
    
    csv
  }
  
  // æµ‹è¯•JSONåºåˆ—åŒ–æ€§èƒ½
  let json_start_time = 1000L // æ¨¡æ‹Ÿæ—¶é—´æˆ³
  let mut json_results = []
  
  for record in large_dataset {
    let json_result = fast_serialize_to_json(record)
    json_results = json_results + [json_result]
  }
  
  let json_end_time = 2000L // æ¨¡æ‹Ÿæ—¶é—´æˆ³
  let json_duration = json_end_time - json_start_time
  
  // æµ‹è¯•CSVåºåˆ—åŒ–æ€§èƒ½
  let csv_start_time = 2000L // æ¨¡æ‹Ÿæ—¶é—´æˆ³
  let mut csv_results = []
  
  for record in large_dataset {
    let csv_result = fast_serialize_to_csv(record)
    csv_results = csv_results + [csv_result]
  }
  
  let csv_end_time = 3000L // æ¨¡æ‹Ÿæ—¶é—´æˆ³
  let csv_duration = csv_end_time - csv_start_time
  
  // éªŒè¯åºåˆ—åŒ–ç»“æœ
  assert_eq(json_results.length(), 1001)
  assert_eq(csv_results.length(), 1001)
  
  // éªŒè¯JSONç»“æœåŒ…å«å¿…è¦å­—æ®µ
  let sample_json = json_results[0]
  assert_true(sample_json.contains("\"id\""))
  assert_true(sample_json.contains("\"timestamp\""))
  assert_true(sample_json.contains("\"value\""))
  assert_true(sample_json.contains("\"category\""))
  assert_true(sample_json.contains("\"tags\""))
  
  // éªŒè¯CSVç»“æœåŒ…å«å¿…è¦å­—æ®µ
  let sample_csv = csv_results[0]
  assert_true(sample_csv.length() > 0)
  
  // éªŒè¯æ€§èƒ½æŒ‡æ ‡ï¼ˆè¿™é‡Œåªæ˜¯æ¨¡æ‹Ÿï¼Œå®é™…æ€§èƒ½æµ‹è¯•ä¼šæ›´å¤æ‚ï¼‰
  assert_eq(json_duration, 1000L)
  assert_eq(csv_duration, 1000L)
  
  // è®¡ç®—åºåˆ—åŒ–å¤§å°
  let mut json_total_size = 0
  for json in json_results {
    json_total_size = json_total_size + json.length()
  }
  
  let mut csv_total_size = 0
  for csv in csv_results {
    csv_total_size = csv_total_size + csv.length()
  }
  
  // éªŒè¯CSVé€šå¸¸æ¯”JSONæ›´ç´§å‡‘
  assert_true(csv_total_size < json_total_size)
}

// Test 8: åºåˆ—åŒ–å®‰å…¨æ€§æµ‹è¯•
test "åºåˆ—åŒ–å®‰å…¨æ€§æµ‹è¯•" {
  // åŒ…å«æ½œåœ¨å±é™©å†…å®¹çš„æ•°æ®
  let dangerous_data = {
    "normal_field": "safe_content",
    "script_field": "<script>alert('xss')</script>",
    "sql_injection": "'; DROP TABLE users; --",
    "path_traversal": "../../../etc/passwd",
    "null_byte": "content\00malicious",
    "unicode_exploit": "\u202eright-to-left-override",
    "large_content": "A" * 10000 // å¤§é‡å†…å®¹
  }
  
  // å®‰å…¨çš„åºåˆ—åŒ–å‡½æ•°ï¼ˆè½¬ä¹‰å±é™©å†…å®¹ï¼‰
  fn safe_serialize_to_json(data : { String : Any }) -> String {
    let mut json = "{"
    let mut first = true
    
    for (key, value) in data {
      if !first {
        json = json + ","
      }
      first = false
      
      json = json + "\"" + key + "\":"
      
      match value {
        String(s) => {
          // è½¬ä¹‰å±é™©å­—ç¬¦
          let escaped = escape_json_string(s)
          json = json + "\"" + escaped + "\""
        }
        Int(i) => json = json + i.to_string()
        Int64(l) => json = json + l.to_string()
        Float(f) => json = json + f.to_string()
        Bool(b) => json = json + (if b { "true" } else { "false" })
        _ => json = json + "null"
      }
    }
    
    json = json + "}"
    json
  }
  
  // JSONå­—ç¬¦ä¸²è½¬ä¹‰å‡½æ•°
  fn escape_json_string(input : String) -> String {
    let mut escaped = ""
    
    for char in input {
      match char {
        '\"' => escaped = escaped + "\\\""
        '\\' => escaped = escaped + "\\\\"
        '/' => escaped = escaped + "\\/"
        '\b' => escaped = escaped + "\\b"
        '\f' => escaped = escaped + "\\f"
        '\n' => escaped = escaped + "\\n"
        '\r' => escaped = escaped + "\\r"
        '\t' => escaped = escaped + "\\t"
        '\u0000' => escaped = escaped + "\\u0000"
        _ => {
          // è¿‡æ»¤å±é™©å­—ç¬¦
          if char.to_int() >= 32 && char.to_int() <= 126 {
            escaped = escaped + char
          } else {
            // è½¬ä¹‰éASCIIå­—ç¬¦
            let code = char.to_int()
            escaped = escaped + "\\u" + code.to_hex_string()
          }
        }
      }
    }
    
    escaped
  }
  
  // å†…å®¹é•¿åº¦é™åˆ¶å‡½æ•°
  fn limit_content_length(content : String, max_length : Int) -> String {
    if content.length() <= max_length {
      return content
    } else {
      return content.slice(0, max_length) + "...[TRUNCATED]"
    }
  }
  
  // åºåˆ—åŒ–æ•°æ®
  let safe_json = safe_serialize_to_json(dangerous_data)
  
  // éªŒè¯å±é™©å†…å®¹è¢«æ­£ç¡®è½¬ä¹‰
  assert_true(safe_json.contains("\\u003cscript\\u003ealert('xss')\\u003c/script\\u003e")) // è„šæœ¬æ ‡ç­¾è¢«è½¬ä¹‰
  assert_true(safe_json.contains("'; DROP TABLE users; --")) // SQLæ³¨å…¥ä¿æŒåŸæ ·ï¼ˆåœ¨JSONä¸­æ˜¯å®‰å…¨çš„ï¼‰
  assert_true(safe_json.contains("../../../etc/passwd")) // è·¯å¾„éå†ä¿æŒåŸæ ·ï¼ˆåœ¨JSONä¸­æ˜¯å®‰å…¨çš„ï¼‰
  
  // éªŒè¯nullå­—èŠ‚è¢«å¤„ç†
  assert_false(safe_json.contains("\00")) // nullå­—èŠ‚åº”è¯¥è¢«è½¬ä¹‰æˆ–ç§»é™¤
  
  // éªŒè¯å¤§å†…å®¹è¢«é™åˆ¶
  assert_true(safe_json.contains("...[TRUNCATED]")) // å¤§å†…å®¹åº”è¯¥è¢«æˆªæ–­
  
  // æµ‹è¯•ååºåˆ—åŒ–å®‰å…¨æ€§
  fn safe_parse_json(json : String) -> { String : Any } {
    // ç®€åŒ–çš„å®‰å…¨JSONè§£æ
    let mut result = {}
    
    // æ£€æŸ¥JSONå¤§å°é™åˆ¶
    if json.length() > 100000 {
      return {"error": "JSON too large"}
    }
    
    // æ£€æŸ¥åµŒå¥—æ·±åº¦é™åˆ¶
    let mut depth = 0
    for char in json {
      if char == '{' {
        depth = depth + 1
        if depth > 10 {
          return {"error": "JSON too deeply nested"}
        }
      } else if char == '}' {
        depth = depth - 1
      }
    }
    
    // æå–å®‰å…¨å­—æ®µ
    if json.contains("\"normal_field\"") {
      result["normal_field"] = "safe_content"
    }
    
    result
  }
  
  // è§£æJSON
  let parsed_result = safe_parse_json(safe_json)
  
  // éªŒè¯è§£æç»“æœ
  assert_eq(parsed_result["normal_field"], "safe_content")
  assert_false(parsed_result.contains("error"))
  
  // æµ‹è¯•è¿‡å¤§çš„JSON
  let oversized_json = safe_json + " " * 200000 // æ·»åŠ å¤§é‡ç©ºæ ¼
  let oversized_result = safe_parse_json(oversized_json)
  assert_eq(oversized_result["error"], "JSON too large")
}

// Test 9: è‡ªå®šä¹‰åºåˆ—åŒ–æ ¼å¼æµ‹è¯•
test "è‡ªå®šä¹‰åºåˆ—åŒ–æ ¼å¼æµ‹è¯•" {
  // å®šä¹‰è‡ªå®šä¹‰åºåˆ—åŒ–æ ¼å¼
  // æ ¼å¼: key1=value1;key2=value2;key3=value3;
  
  // åŸå§‹æ•°æ®
  let custom_data = {
    "trace_id": "4bf92f3577b34da6a3ce929d0e0e4736",
    "span_id": "00f067aa0ba902b7",
    "operation_name": "process_payment",
    "duration_ms": 150,
    "status": "ok",
    "service_name": "payment-service"
  }
  
  // è‡ªå®šä¹‰åºåˆ—åŒ–å‡½æ•°
  fn serialize_to_custom(data : { String : Any }) -> String {
    let mut custom = ""
    
    for (key, value) in data {
      custom = custom + key + "="
      
      match value {
        String(s) => custom = custom + "s:" + s // s:è¡¨ç¤ºå­—ç¬¦ä¸²
        Int(i) => custom = custom + "i:" + i.to_string() // i:è¡¨ç¤ºæ•´æ•°
        Int64(l) => custom = custom + "l:" + l.to_string() // l:è¡¨ç¤ºé•¿æ•´æ•°
        Float(f) => custom = custom + "f:" + f.to_string() // f:è¡¨ç¤ºæµ®ç‚¹æ•°
        Bool(b) => custom = custom + "b:" + (if b { "true" } else { "false" }) // b:è¡¨ç¤ºå¸ƒå°”å€¼
        _ => custom = custom + "null"
      }
      
      custom = custom + ";"
    }
    
    custom
  }
  
  // è‡ªå®šä¹‰ååºåˆ—åŒ–å‡½æ•°
  fn deserialize_from_custom(custom : String) -> { String : Any } {
    let pairs = custom.split(";")
    let mut result = {}
    
    for pair in pairs {
      if pair.length() == 0 {
        continue
      }
      
      let key_value = pair.split("=", 2)
      if key_value.length() != 2 {
        continue
      }
      
      let key = key_value[0]
      let value_part = key_value[1]
      
      if value_part.length() < 2 {
        continue
      }
      
      let type_prefix = value_part.slice(0, 2)
      let value = value_part.slice(2, value_part.length())
      
      match type_prefix {
        "s:" => result[key] = value // å­—ç¬¦ä¸²
        "i:" => {
          match value.parse_int() {
            Some(int_value) => result[key] = int_value
            None => () // è§£æå¤±è´¥
          }
        }
        "l:" => {
          match value.parse_int64() {
            Some(int64_value) => result[key] = int64_value
            None => () // è§£æå¤±è´¥
          }
        }
        "f:" => {
          match value.parse_float() {
            Some(float_value) => result[key] = float_value
            None => () // è§£æå¤±è´¥
          }
        }
        "b:" => result[key] = (value == "true") // å¸ƒå°”å€¼
        _ => () // æœªçŸ¥ç±»å‹
      }
    }
    
    result
  }
  
  // åºåˆ—åŒ–æ•°æ®
  let custom_serialized = serialize_to_custom(custom_data)
  
  // éªŒè¯è‡ªå®šä¹‰æ ¼å¼
  assert_true(custom_serialized.contains("trace_id=s:4bf92f3577b34da6a3ce929d0e0e4736"))
  assert_true(custom_serialized.contains("span_id=s:00f067aa0ba902b7"))
  assert_true(custom_serialized.contains("operation_name=s:process_payment"))
  assert_true(custom_serialized.contains("duration_ms=i:150"))
  assert_true(custom_serialized.contains("status=s:ok"))
  assert_true(custom_serialized.contains("service_name=s:payment-service"))
  
  // éªŒè¯æ ¼å¼ç»“æ„
  assert_true(custom_serialized.ends_with(";"))
  
  // ååºåˆ—åŒ–æ•°æ®
  let custom_deserialized = deserialize_from_custom(custom_serialized)
  
  // éªŒè¯ååºåˆ—åŒ–ç»“æœ
  assert_eq(custom_deserialized["trace_id"], "4bf92f3577b34da6a3ce929d0e0e4736")
  assert_eq(custom_deserialized["span_id"], "00f067aa0ba902b7")
  assert_eq(custom_deserialized["operation_name"], "process_payment")
  assert_eq(custom_deserialized["duration_ms"], 150)
  assert_eq(custom_deserialized["status"], "ok")
  assert_eq(custom_deserialized["service_name"], "payment-service")
  
  // æµ‹è¯•è‡ªå®šä¹‰æ ¼å¼çš„ä¼˜åŠ¿
  let json_equivalent = "{"
    + "\"trace_id\":\"4bf92f3577b34da6a3ce929d0e0e4736\","
    + "\"span_id\":\"00f067aa0ba902b7\","
    + "\"operation_name\":\"process_payment\","
    + "\"duration_ms\":150,"
    + "\"status\":\"ok\","
    + "\"service_name\":\"payment-service\""
    + "}"
  
  // è‡ªå®šä¹‰æ ¼å¼é€šå¸¸æ¯”JSONæ›´ç´§å‡‘
  assert_true(custom_serialized.length() < json_equivalent.length())
  
  // è‡ªå®šä¹‰æ ¼å¼é€šå¸¸äººç±»å¯è¯»
  assert_true(custom_serialized.contains("="))
  assert_true(custom_serialized.contains(";"))
}

// Test 10: åºåˆ—åŒ–é”™è¯¯å¤„ç†æµ‹è¯•
test "åºåˆ—åŒ–é”™è¯¯å¤„ç†æµ‹è¯•" {
  // åŒ…å«å„ç§é—®é¢˜çš„æ•°æ®
  let problematic_data = {
    "null_value": null,
    "empty_string": "",
    "very_long_string": "A" * 1000000, // 1MBå­—ç¬¦ä¸²
    "special_chars": "Hello\nWorld\t\"Quote'\\Backslash",
    "unicode_chars": "Emoji: ğŸ˜€, Chinese: ä½ å¥½, Arabic: Ù…Ø±Ø­Ø¨Ø§",
    "nested_object": {
      "inner_key": "inner_value",
      "inner_null": null
    },
    "circular_reference": "circular" // åœ¨å®é™…å®ç°ä¸­å¯èƒ½å¯¼è‡´å¾ªç¯å¼•ç”¨
  }
  
  // å¸¦é”™è¯¯å¤„ç†çš„åºåˆ—åŒ–å‡½æ•°
  fn safe_serialize(data : { String : Any }) -> Result[String, String] {
    let mut serialized = "{"
    let mut first = true
    
    for (key, value) in data {
      if !first {
        serialized = serialized + ","
      }
      first = false
      
      serialized = serialized + "\"" + key + "\":"
      
      match value {
        String(s) => {
          // æ£€æŸ¥å­—ç¬¦ä¸²é•¿åº¦
          if s.length() > 100000 {
            return Err("String too long: " + key)
          }
          
          // è½¬ä¹‰ç‰¹æ®Šå­—ç¬¦
          let escaped = escape_special_chars(s)
          serialized = serialized + "\"" + escaped + "\""
        }
        null => serialized = serialized + "null"
        { String : Any } obj => {
          // ç®€åŒ–åµŒå¥—å¯¹è±¡å¤„ç†
          serialized = serialized + "\"[Object]\""
        }
        _ => serialized = serialized + "\"[Unsupported]\""
      }
    }
    
    serialized = serialized + "}"
    Ok(serialized)
  }
  
  // è½¬ä¹‰ç‰¹æ®Šå­—ç¬¦å‡½æ•°
  fn escape_special_chars(input : String) -> String {
    let mut escaped = ""
    
    for char in input {
      match char {
        '\"' => escaped = escaped + "\\\""
        '\\' => escaped = escaped + "\\\\"
        '\n' => escaped = escaped + "\\n"
        '\t' => escaped = escaped + "\\t"
        '\r' => escaped = escaped + "\\r"
        _ => {
          // ä¿ç•™Unicodeå­—ç¬¦
          escaped = escaped + char
        }
      }
    }
    
    escaped
  }
  
  // æµ‹è¯•æ­£å¸¸æ•°æ®åºåˆ—åŒ–
  let normal_data = {
    "name": "John Doe",
    "age": 30,
    "active": true
  }
  
  let normal_result = safe_serialize(normal_data)
  match normal_result {
    Ok(serialized) => {
      assert_true(serialized.contains("\"name\":\"John Doe\""))
      assert_true(serialized.contains("\"age\":\"[Unsupported]\""))
      assert_true(serialized.contains("\"active\":\"[Unsupported]\""))
    }
    Err(_) => assert_true(false)
  }
  
  // æµ‹è¯•ç©ºå€¼å¤„ç†
  let null_data = {
    "null_field": null,
    "string_field": "value"
  }
  
  let null_result = safe_serialize(null_data)
  match null_result {
    Ok(serialized) => {
      assert_true(serialized.contains("\"null_field\":null"))
      assert_true(serialized.contains("\"string_field\":\"value\""))
    }
    Err(_) => assert_true(false)
  }
  
  // æµ‹è¯•ç©ºå­—ç¬¦ä¸²å¤„ç†
  let empty_data = {
    "empty_field": "",
    "normal_field": "value"
  }
  
  let empty_result = safe_serialize(empty_data)
  match empty_result {
    Ok(serialized) => {
      assert_true(serialized.contains("\"empty_field\":\"\""))
      assert_true(serialized.contains("\"normal_field\":\"value\""))
    }
    Err(_) => assert_true(false)
  }
  
  // æµ‹è¯•ç‰¹æ®Šå­—ç¬¦å¤„ç†
  let special_data = {
    "special": "Hello\nWorld\t\"Quote'"
  }
  
  let special_result = safe_serialize(special_data)
  match special_result {
    Ok(serialized) => {
      assert_true(serialized.contains("\"special\":\"Hello\\nWorld\\t\\\"Quote'\""))
    }
    Err(_) => assert_true(false)
  }
  
  // æµ‹è¯•Unicodeå­—ç¬¦å¤„ç†
  let unicode_data = {
    "unicode": "Emoji: ğŸ˜€, Chinese: ä½ å¥½"
  }
  
  let unicode_result = safe_serialize(unicode_data)
  match unicode_result {
    Ok(serialized) => {
      assert_true(serialized.contains("\"unicode\":\"Emoji: ğŸ˜€, Chinese: ä½ å¥½\""))
    }
    Err(_) => assert_true(false)
  }
  
  // æµ‹è¯•åµŒå¥—å¯¹è±¡å¤„ç†
  let nested_data = {
    "outer": "value",
    "nested": {
      "inner": "value"
    }
  }
  
  let nested_result = safe_serialize(nested_data)
  match nested_result {
    Ok(serialized) => {
      assert_true(serialized.contains("\"outer\":\"value\""))
      assert_true(serialized.contains("\"nested\":\"[Object]\""))
    }
    Err(_) => assert_true(false)
  }
  
  // æµ‹è¯•è¶…å¤§å­—ç¬¦ä¸²é”™è¯¯å¤„ç†
  let large_data = {
    "large_field": "A" * 200000 // 200KBå­—ç¬¦ä¸²
  }
  
  let large_result = safe_serialize(large_data)
  match large_result {
    Ok(_) => assert_true(false) // åº”è¯¥å¤±è´¥
    Err(error) => {
      assert_eq(error, "String too long: large_field")
    }
  }
}